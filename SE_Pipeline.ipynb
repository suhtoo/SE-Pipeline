{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RG1-0Idw1xEG"
      ],
      "authorship_tag": "ABX9TyMokg6RmuuB6pGxJNlKiWsM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhtoo/SE-Pipeline/blob/main/SE_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Enrichment Pipeline with OpenBIM\n",
        "<a name=\"semantic-enrichment-pipeline-with-openbim\"></a>\n",
        "\n",
        "This notebook demonstrates the case study implementation of Semantic Enrichment Pipeline in OpenBIM (IFC) and ASB-ING dataset in JSON format.\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "<a name=\"table-of-contents\"></a>\n",
        "1. [IFC to RDF](#ifc-to-rdf)\n",
        "2. [ASB to RDF](#asb-to-rdf)\n",
        "3. [Graph Merging](#graph-merging)\n",
        "4. [Ontology Linking](#ontology-linking)\n",
        "5. [Graph Completion](#graph-completion)\n",
        "6. [Querying and Validation](#querying-and-validation)\n",
        "\n",
        "   [Visualisation](#visualisation)"
      ],
      "metadata": {
        "id": "Te2rvM9lfs05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies and Create Directories"
      ],
      "metadata": {
        "id": "5RhbjeDadkt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ifcopenshell pandas rdflib owlrl pyvis requests"
      ],
      "metadata": {
        "id": "34pqNNYOFqY2",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e64ad2-2f9a-4390-b79c-0e126e9f251c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ifcopenshell\n",
            "  Downloading ifcopenshell-0.8.1.post1-py311-none-manylinux_2_31_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting owlrl\n",
            "  Downloading owlrl-7.1.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from ifcopenshell) (2.0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ifcopenshell) (1.26.4)\n",
            "Collecting isodate (from ifcopenshell)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from ifcopenshell) (2.8.2)\n",
            "Collecting lark (from ifcopenshell)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from ifcopenshell) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib) (3.2.1)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.1.5)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis) (3.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->ifcopenshell) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Downloading ifcopenshell-0.8.1.post1-py311-none-manylinux_2_31_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.1.3-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.9/564.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading owlrl-7.1.3-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdflib, lark, jedi, isodate, owlrl, ifcopenshell, pyvis\n",
            "Successfully installed ifcopenshell-0.8.1.post1 isodate-0.7.2 jedi-0.19.2 lark-1.2.2 owlrl-7.1.3 pyvis-0.3.2 rdflib-7.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The functions in this notebook use default directories:\n",
        "In \"data\" folder, upload the data sources like IFC files, JSON files and excel file for Mapping table. The output of the functions are saved in \"output\" folder if not specified. The directories can be manually created or run the script below."
      ],
      "metadata": {
        "id": "Iyg5kreFe3eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create data folder if it doesn't exist\n",
        "data_folder = \"data\"\n",
        "if not os.path.exists(data_folder):\n",
        "    os.makedirs(data_folder)\n",
        "    print(f\"Created data folder: {data_folder}\")\n",
        "else:\n",
        "    print(f\"Data folder '{data_folder}' already exists.\")\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "output_folder = \"output\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "    print(f\"Created output folder: {output_folder}\")\n",
        "else:\n",
        "    print(f\"Output folder '{output_folder}' already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBoJ-7Dy-Nb9",
        "outputId": "9a4d44e4-9497-42a4-b0ac-02b6dcda9d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created data folder: data\n",
            "Created output folder: output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. IFC to RDF"
      ],
      "metadata": {
        "id": "-AdbNQAum0_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Attributes from IFC\n",
        "\n",
        "\n",
        "This can later be used to formulate alignment file between IFC model elements and other dataset."
      ],
      "metadata": {
        "id": "U10FdpFGgrec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ifcopenshell\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def ifc_extractor(ifc_file_path: str):\n",
        "    \"\"\"\n",
        "    Extracts all available attributes from IFC elements and saves them to a CSV file in the 'output' folder.\n",
        "\n",
        "    Args:\n",
        "        ifc_file_path (str): Path to the IFC file.\n",
        "    \"\"\"\n",
        "\n",
        "    output_path = Path(\"output\", \"ifc_attributes.csv\") # Default output path in 'output' folder\n",
        "\n",
        "    # Load the IFC file\n",
        "    ifc_file = ifcopenshell.open(ifc_file_path)\n",
        "\n",
        "    # Get all elements\n",
        "    elements = ifc_file.by_type('IfcObject')\n",
        "\n",
        "    # Initialize list to store element data\n",
        "    elements_data = []\n",
        "\n",
        "    for element in elements:\n",
        "        # Basic element data\n",
        "        element_data = {\n",
        "            'ElementType': element.is_a(),\n",
        "            'PredefinedType': element.PredefinedType if hasattr(element, 'PredefinedType') else None,\n",
        "            'GlobalId': element.GlobalId,\n",
        "            'id': element.id(),\n",
        "            'Name': getattr(element, 'Name', None),\n",
        "            'Description': getattr(element, 'Description', None),\n",
        "            'ObjectType': getattr(element, 'ObjectType', None),\n",
        "        }\n",
        "\n",
        "        # Get property sets\n",
        "        if element.IsDefinedBy:\n",
        "            for definition in element.IsDefinedBy:\n",
        "                if definition.is_a('IfcRelDefinesByProperties'):\n",
        "                    pset = definition.RelatingPropertyDefinition\n",
        "                    if pset.is_a('IfcPropertySet'):\n",
        "                        for prop in pset.HasProperties:\n",
        "                            if hasattr(prop, 'NominalValue') and prop.NominalValue is not None:\n",
        "                                element_data[f\"{pset.Name}_{prop.Name}\"] = prop.NominalValue.wrappedValue\n",
        "\n",
        "        elements_data.append(element_data)\n",
        "\n",
        "    # Convert to DataFrame and save to CSV\n",
        "    df = pd.DataFrame(elements_data)\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"{output_path} created and saved with {len(df)} attributes\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ifc_extractor = ifc_extractor(\"/content/data/UKA_UK_Aachen_IFC_02.ifc\")\n"
      ],
      "metadata": {
        "id": "7XcbZS9Igv9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create IFC Instance Graph\n",
        "\n",
        "Convert IFC file to RDF and save as TTL file."
      ],
      "metadata": {
        "id": "upLyRbGmL2Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "import ifcopenshell\n",
        "from rdflib import Graph, Namespace, URIRef, Literal\n",
        "from pathlib import Path\n",
        "import urllib.parse\n",
        "\n",
        "def create_namespaces():\n",
        "    \"\"\"Create and return commonly used namespaces.\"\"\"\n",
        "    return {\n",
        "        'INST': Namespace(\"http://ifc-instance.org/instances/\"),\n",
        "        'RDF': Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"),\n",
        "        'RDFS': Namespace(\"http://www.w3.org/2000/01/rdf-schema#\"),\n",
        "        'OWL': Namespace(\"http://www.w3.org/2002/07/owl#\"),\n",
        "        'BSDD': Namespace(\"https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/\"),\n",
        "        'PROP': Namespace(\"https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/prop/\"),\n",
        "        'BROT': Namespace(\"https://w3id.org/brot#\"),\n",
        "        'BRCOMP': Namespace(\"https://w3id.org/brcomp#\"),\n",
        "        'ASB': Namespace(\"http://asb-example.org/\")\n",
        "\n",
        "    }\n",
        "\n",
        "def create_and_bind_graph():\n",
        "    \"\"\"Create a new graph and bind namespaces.\"\"\"\n",
        "    g = Graph()\n",
        "    namespaces = create_namespaces()\n",
        "\n",
        "    # Bind all namespaces\n",
        "    for prefix, ns in namespaces.items():\n",
        "        g.bind(prefix.lower(), ns)\n",
        "\n",
        "    return g, namespaces\n",
        "\n",
        "def clean_uri_string(s: str) -> str:\n",
        "    \"\"\"Clean string to make it URI-safe.\"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    cleaned = s.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\".\", \"_\")\n",
        "    return urllib.parse.quote(cleaned)"
      ],
      "metadata": {
        "id": "4cNiGuo_KWMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ifc_rdf_converter(ifc_file_path: str):\n",
        "    \"\"\"\n",
        "    Convert IFC file to RDF and save as TTL file in the 'output' folder.\n",
        "\n",
        "    Args:\n",
        "        ifc_file_path (str): Path to the IFC file.\n",
        "    \"\"\"\n",
        "\n",
        "    output_file = Path(\"output\", \"ifc_graph.ttl\")  # Default output path in 'output' folder\n",
        "\n",
        "    # Create graph and get namespaces\n",
        "    g, ns = create_and_bind_graph()\n",
        "\n",
        "    def get_element_uri(element_id: int) -> URIRef:\n",
        "        \"\"\"Create URI for an element.\"\"\"\n",
        "        return URIRef(ns['INST'][f\"{element_id}\"])\n",
        "\n",
        "    def process_relationship(relationship):\n",
        "        \"\"\"Process IFC relationship and add triples to graph.\"\"\"\n",
        "        rel_type = relationship.is_a()\n",
        "\n",
        "        # Get common relating element\n",
        "        relating_element = None\n",
        "        if hasattr(relationship, 'RelatingElement'):\n",
        "            relating_element = relationship.RelatingElement\n",
        "        elif hasattr(relationship, 'RelatingStructure'):\n",
        "            relating_element = relationship.RelatingStructure\n",
        "        elif hasattr(relationship, 'RelatingObject'):\n",
        "            relating_element = relationship.RelatingObject\n",
        "\n",
        "\n",
        "        # Get common related elements\n",
        "        related_elements = []\n",
        "        if hasattr(relationship, 'RelatedElements'):\n",
        "            related_elements.extend(relationship.RelatedElements)\n",
        "        elif hasattr(relationship, 'RelatedElement'):\n",
        "            related_elements.append(relationship.RelatedElement)\n",
        "        elif hasattr(relationship, 'RelatedObjects'):\n",
        "            related_elements.extend(relationship.RelatedObjects)\n",
        "        elif hasattr(relationship, 'RelatedObject'):\n",
        "            related_elements.append(relationship.RelatedObject)\n",
        "\n",
        "\n",
        "        # Add relationship triples\n",
        "        if relating_element and hasattr(relating_element, 'id'):\n",
        "            relating_uri = get_element_uri(relating_element.id())\n",
        "            for related_element in related_elements:\n",
        "                if hasattr(related_element, 'id'):\n",
        "                    related_uri = get_element_uri(related_element.id())\n",
        "                    g.add((relating_uri, ns['INST'][rel_type], related_uri))\n",
        "\n",
        "    # Load IFC file\n",
        "    ifc_file = ifcopenshell.open(ifc_file_path)\n",
        "\n",
        "    # Process elements\n",
        "    for element in ifc_file.by_type('IfcProduct'):\n",
        "        element_uri = get_element_uri(element.id())\n",
        "\n",
        "        # Add element type\n",
        "        element_type = element.is_a()\n",
        "        if hasattr(element, \"PredefinedType\") and element.PredefinedType not in [\"NOTDEFINED\", \"USERDEFINED\", None, '*']:\n",
        "            element_type = f\"{element.is_a()}{element.PredefinedType}\"\n",
        "        g.add((element_uri, ns['RDF'].type, URIRef(ns['BSDD'][clean_uri_string(element_type)])))\n",
        "\n",
        "        # Add basic attributes\n",
        "        if element.GlobalId:\n",
        "            g.add((element_uri, ns['PROP'].GlobalId, Literal(element.GlobalId)))\n",
        "\n",
        "        if hasattr(element, 'Name') and element.Name:\n",
        "            g.add((element_uri, ns['RDFS'].label, Literal(element.Name)))\n",
        "\n",
        "        if hasattr(element, 'Description') and element.Description:\n",
        "            g.add((element_uri, ns['RDFS'].comment, Literal(element.Description)))\n",
        "\n",
        "        if hasattr(element, 'ObjectType') and element.ObjectType:\n",
        "            g.add((element_uri, ns['PROP'].ObjectType, Literal(element.ObjectType)))\n",
        "\n",
        "    # Process relationships\n",
        "    for relationship in ifc_file.by_type('IfcRelationship'):\n",
        "        process_relationship(relationship)\n",
        "\n",
        "    g.serialize(destination=str(output_file), format=\"turtle\")\n",
        "    print(f\"{output_file} created and saved with {len(g)} triples\")\n",
        "    print(f\"Number of relationships: {len(ifc_file.by_type('IfcRelationship'))}\")\n",
        "\n",
        "    return g\n",
        "\n",
        "# Execution\n",
        "# ifc_graph = ifc_rdf_converter(\"/content/data/UKA_UK_Aachen_IFC_02.ifc\")"
      ],
      "metadata": {
        "id": "Q7nBOKTFKacp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. JSON to RDF"
      ],
      "metadata": {
        "id": "joMRnyPcnH_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replace 15-digit key with description."
      ],
      "metadata": {
        "id": "B3C-kADT0AIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from rdflib import Graph\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "\n",
        "def key_value_mapper(input_json, output_filepath=None):\n",
        "    \"\"\"\n",
        "    Replaces 15-digit keys in the JSON data with their corresponding descriptions\n",
        "    from an ontology.\n",
        "\n",
        "    Args:\n",
        "        input_json (str): Path to the input JSON file.\n",
        "        output_filepath (str, optional): Path to save the mapped JSON data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the ontology that contains key-value descriptions\n",
        "    g = Graph()\n",
        "    g.parse(\"https://annegoebels.github.io/asb/oldkeys/ontology.ttl\", format='ttl')\n",
        "\n",
        "\n",
        "    # Create lookup dictionary\n",
        "    lookup_dict = {}\n",
        "    pattern = re.compile(r\"#(\\d{15})_(.+)$\")  # Match 15-digit number and class name\n",
        "    for s in g.subjects():\n",
        "        s_str = str(s)\n",
        "        match = pattern.search(s_str)\n",
        "        if match:\n",
        "            number, class_name = match.groups()\n",
        "            if number not in lookup_dict:\n",
        "                lookup_dict[number] = class_name\n",
        "\n",
        "    # Load JSON data\n",
        "    if isinstance(input_json, str):\n",
        "        with open(input_json, 'r') as file:\n",
        "            data = json.load(file)\n",
        "    else:\n",
        "        data = input_json\n",
        "\n",
        "    # Initialize counters\n",
        "    total_processed = 0\n",
        "    matches_found = 0\n",
        "\n",
        "    # Process each file's data\n",
        "    for file_key, records in data.items():\n",
        "        # Process each record in the file\n",
        "        for record in records:\n",
        "            # Process each field in the record\n",
        "            for field_key, field_value in record.items():\n",
        "                if isinstance(field_value, str) and len(field_value) == 15 and field_value.isdigit():\n",
        "                    total_processed += 1\n",
        "                    class_name = lookup_dict.get(field_value)\n",
        "                    if class_name:\n",
        "                        matches_found += 1\n",
        "                        record[field_key] = class_name  # Replacement key with value\n",
        "\n",
        "    # Save if output path is provided\n",
        "    if output_filepath is None:\n",
        "        # Default output path in 'data' folder if not specified\n",
        "        output_filepath = input_json.replace('.json', '_mapped.json')\n",
        "\n",
        "    with open(output_filepath, 'w') as file:\n",
        "        json.dump(data, file, indent=2)\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"\\nStatistics Key-Value Map:\")\n",
        "    print(f\"Total 15-digit values processed: {total_processed}\")\n",
        "    print(f\"Matches found: {matches_found}\")\n",
        "    print(f\"Number of files processed: {len(data)}\\n\")\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O9BslyzKw2fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Subject-Predicate-Object from JSON"
      ],
      "metadata": {
        "id": "a4Yg8DQ84lGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "def json_spo_extractor(json_file_path, output_path=None):\n",
        "    \"\"\"\n",
        "    Extracts Subject-Predicate-Object triples from JSON data and saves them to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        json_file_path (str): Path to the input JSON file.\n",
        "        output_path (str, optional): Path to save the extracted SPO triples.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read JSON file\n",
        "    with open(json_file_path) as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Define differnt ASBID for Bauwerk, Teilbauwerk and Brueke\n",
        "    asbid_mapping = {\n",
        "        \"ges_bw.csv\": \"BWNR\",\n",
        "        \"teil_bw.csv\": \"ID_NR\",\n",
        "        \"bruecke.csv\": \"REF_BRUCKE\"\n",
        "        }\n",
        "\n",
        "    # List to store all rows\n",
        "    rows = []\n",
        "\n",
        "    # Process each CSV file\n",
        "    for category, records in data.items():\n",
        "        # Get subject\n",
        "        subject = category\n",
        "\n",
        "        # Determine which ASBID key to use using asbid_mapping dictionary\n",
        "        asbid_key = asbid_mapping.get(category, 'IDENT') # Default to IDENT if not in mapping\n",
        "\n",
        "        # Process each dictionary in the CSV\n",
        "        for record in records:\n",
        "            if isinstance(record, dict):\n",
        "                # Get ASBID using appropriate key\n",
        "                asbid = record.get(asbid_key, '')\n",
        "\n",
        "                # Process each key-value pair\n",
        "                for key, value in record.items():\n",
        "                    # Check if OBJECT value is not \"NaN\" or \"0\" or \"0.0\"\n",
        "                    if value != \"NaN\" and value != \"***\" and value != \" ***\":\n",
        "                      rows.append({\n",
        "                          'ASBID': asbid,\n",
        "                          'CATEGORY': subject,\n",
        "                          'PROPERTY': key,\n",
        "                          'OBJECT': value,\n",
        "                    })\n",
        "\n",
        "    # Create DataFrame and save to CSV\n",
        "    df_SPO = pd.DataFrame(rows)\n",
        "\n",
        "    # Reorder columns to match specified order\n",
        "    df_SPO = df_SPO[['ASBID', 'CATEGORY', 'PROPERTY', 'OBJECT']]\n",
        "    print(f\"Total rows in SPO: {len(df_SPO)} \\n\")\n",
        "\n",
        "    # Save if output path is provided, else default to 'output'\n",
        "    if output_path is None:\n",
        "        output_path = os.path.join(\"output\",'asb_SPO.csv')\n",
        "\n",
        "    df_SPO.to_csv(output_path, index=False)\n",
        "\n",
        "    return df_SPO\n",
        "\n",
        "# Execute\n",
        "# df_SPO = json_spo_extractor(\"/content/data/extracted_B115_mapped.json\")"
      ],
      "metadata": {
        "id": "yUsnAOnjnK1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map to a more descriptive subject name and map datatype for object value"
      ],
      "metadata": {
        "id": "ZoGKsa7YEQyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def datatype_mapper(map_excel_path, df):\n",
        "    \"\"\"\n",
        "    Maps datatypes and properties to more descriptive names using a mapping Excel file.\n",
        "\n",
        "    Args:\n",
        "        map_excel_path (str): Path to the mapping Excel file.\n",
        "        df (pd.DataFrame): DataFrame containing the SPO triples.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read excel sheet\n",
        "    map_csv = pd.read_excel(map_excel_path, sheet_name='MAPPING')\n",
        "\n",
        "    # Create mapping dictionaries\n",
        "    class_mapping = dict(zip(map_csv[\"Table\"], map_csv[\"Table_Name\"]))\n",
        "    datatype_mapping = dict(zip(map_csv[\"Attribute\"], map_csv[\"Datatype\"]))\n",
        "    # property_mapping = dict(zip(map_csv[\"Attribute\"], map_csv[\"Attribute_FullText\"]))\n",
        "\n",
        "    # Replace SUBJECT values using class_mapping\n",
        "    df['CATEGORY'] = df['CATEGORY'].replace(class_mapping)\n",
        "\n",
        "    # Add a new column for datatype based on the PROPERTY column\n",
        "    df['DATATYPE'] = df['PROPERTY'].map(datatype_mapping) # Map datatype based on 'PROPERTY' column\n",
        "\n",
        "    # Replace PROPERTY values using property_mapping\n",
        "    # df['PROPERTY'] = df['PROPERTY'].replace(property_mapping)\n",
        "\n",
        "    #print(len(df[\"CATEGORY\"].unique()))\n",
        "\n",
        "    # Save the DataFrame to CSV, replacing existing file\n",
        "    output_path = os.path.join(\"output\", \"asb_SPO.csv\")  # Path to asb_SPO.csv in the output folder\n",
        "    df.to_csv(output_path, index=False)  # Overwrite the existing file if it exists\n",
        "\n",
        "    return df\n",
        "\n",
        "# Execute\n",
        "# datatype_mapper(\"/content/data/mapping.xlsx\", df_SPO)"
      ],
      "metadata": {
        "id": "MivOTDpd-vjb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main SPO Extractor Function"
      ],
      "metadata": {
        "id": "UxOVnmIyhcLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_spo_extractor(input_json_file: str, mapping_table: str, output_spo_file=None):\n",
        "    \"\"\"\n",
        "    Main function to extract and process SPO triples from a JSON file,\n",
        "    apply key-value mapping and datatype mapping, and save to a CSV.\n",
        "\n",
        "    Args:\n",
        "        input_json_file (str): Path to the input JSON file.\n",
        "        mapping_table (str): Path to the mapping table (Excel file).\n",
        "        output_spo_file (str, optional): Path to save the extracted SPO triples.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Key-Value Mapping:\n",
        "    mapped_data = key_value_mapper(input_json_file)\n",
        "\n",
        "    # 2. JSON to SPO Extraction:\n",
        "    # Pass the original file path for reading the JSON data\n",
        "    asb_SPO = json_spo_extractor(input_json_file, output_path=output_spo_file)\n",
        "\n",
        "    # 3. Datatype Mapping:\n",
        "    asb_SPO = datatype_mapper(mapping_table, asb_SPO)\n",
        "\n",
        "    # 4. Save to CSV:\n",
        "    if output_spo_file is None:\n",
        "        output_path = os.path.join(\"output\", \"asb_SPO.csv\")  # Default output path\n",
        "    else:\n",
        "        output_path = output_spo_file  # Use provided output path\n",
        "\n",
        "    asb_SPO.to_csv(output_path, index=False)\n",
        "\n",
        "    return asb_SPO\n",
        "\n",
        "# Example Usage\n",
        "# json_input = \"/content/data/extracted_B115.json\"\n",
        "# mapping_table = \"/content/data/mapping.xlsx\"\n",
        "# asb_df = main_spo_extractor(json_input, mapping_table)"
      ],
      "metadata": {
        "id": "kY0F4QmleUKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate RDF"
      ],
      "metadata": {
        "id": "KZaXQwJl8929"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to clean the strings\n",
        "import pandas as pd\n",
        "from rdflib import Graph, Literal, Namespace, URIRef\n",
        "from rdflib.namespace import RDF, RDFS, XSD\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def clean_string(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "\n",
        "    # Convert to string if not already\n",
        "    text = str(text)\n",
        "\n",
        "    # Replace German special characters\n",
        "    replacements = {\n",
        "        'ä': 'ae', 'ö': 'oe', 'ü': 'ue', 'ß': 'ss',\n",
        "        'Ä': 'Ae', 'Ö': 'Oe', 'Ü': 'Ue'\n",
        "    }\n",
        "    for char, replacement in replacements.items():\n",
        "        text = text.replace(char, replacement)\n",
        "\n",
        "    # Remove accents\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFKD', text)\n",
        "                  if not unicodedata.combining(c))\n",
        "\n",
        "    # Replace spaces and special chars with underscore\n",
        "    text = re.sub(r'[^a-zA-Z0-9]+', '_', text)\n",
        "\n",
        "    # Remove leading/trailing underscores\n",
        "    text = text.strip('_')\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def get_xsd_datatype(datatype: str):\n",
        "    \"\"\"Map datatype string to XSD datatype.\"\"\"\n",
        "    datatype_mapping = {\n",
        "        'double': XSD.float,\n",
        "        'dateTime': XSD.dateTime,\n",
        "        'year': XSD.year,\n",
        "        'text': XSD.string,\n",
        "        'int': XSD.integer,\n",
        "        'boolean': XSD.boolean,\n",
        "        'long': XSD.integer,\n",
        "        'float': XSD.float,\n",
        "        # Add more mappings as needed\n",
        "    }\n",
        "    return datatype_mapping.get(datatype, None)\n"
      ],
      "metadata": {
        "id": "ZZ8krxxF9BwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def json_rdf_converter(df, valid_categories):\n",
        "    \"\"\"\n",
        "    Converts a DataFrame of SPO triples to an RDF graph and saves it as a Turtle file.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the SPO triples.\n",
        "        valid_categories (list): List of valid categories for filtering the data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define Namespace\n",
        "    ASB = Namespace(\"http://asb-example.org/\")\n",
        "\n",
        "    # Create graph and bind namespaces\n",
        "    g = Graph()\n",
        "    g.bind(\"asb\", ASB)\n",
        "\n",
        "    # Clean the relevant columns\n",
        "    df['CATEGORY'] = df['CATEGORY'].apply(clean_string)\n",
        "    df['PROPERTY'] = df['PROPERTY'].apply(clean_string)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Get the subject from the row and clean it\n",
        "        category = row['CATEGORY']\n",
        "\n",
        "        # Check if the class is in the list of valid_categories\n",
        "        if category not in valid_categories:\n",
        "            continue\n",
        "\n",
        "        # Create RDF triples\n",
        "        subject = URIRef(ASB[f\"{clean_string(row['ASBID'])}\"])\n",
        "        predicate = URIRef(ASB[row['PROPERTY']])\n",
        "\n",
        "        # Use the value in 'OBJECT' column directly\n",
        "        if pd.notna(row['OBJECT']):\n",
        "            datatype = row['DATATYPE'] if isinstance(row['DATATYPE'], str) else None\n",
        "\n",
        "            if datatype:  # If datatype is present, create a Literal with datatype\n",
        "                xsd_datatype = get_xsd_datatype(datatype) if datatype else None\n",
        "                obj = Literal(row['OBJECT'], datatype=xsd_datatype) if xsd_datatype else Literal(row['OBJECT'])\n",
        "            else:  # If datatype is empty, create a resource with 'asb:' prefix\n",
        "                obj = URIRef(ASB[clean_string(row['OBJECT'])])\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # Replace \"SUBJECT\" with \"CATEGORY\"\n",
        "        g.add((subject, RDF.type, URIRef(ASB[f\"ASB_Pset_{row['CATEGORY']}\"])))\n",
        "        g.add((subject, predicate, obj)) if obj else None\n",
        "\n",
        "    # Serialize the graph to the default output file\n",
        "    output_file = os.path.join(\"output\", \"asb_graph.ttl\")  # Default output path\n",
        "    g.serialize(format='turtle', destination=output_file)\n",
        "    print(f\"{output_file} created and saved with {len(g)} triples\")\n",
        "\n",
        "    return g\n",
        "\n",
        "'''\n",
        "# Execution\n",
        "valid_categories = ['Bauwerk', 'Teilbauwerk', 'Bruecke',\n",
        "                   'BelagAbdichtung', 'Ausstattungen', 'fhrb_bel.csv', 'Gruendung', 'Kappe', 'Lager',\n",
        "                   'Leitung', 'Schutzeinrichtungen', 'StatischesSystem_Tragfaehigkeit', 'Vorspannung',\n",
        "                   'Fahrbahnuebergang', 'Feld']\n",
        "\n",
        "graph = json_rdf_converter(df_SPO, valid_categories)\n",
        "\n",
        "\n",
        "# Print numbers of triples\n",
        "print(f\"Number of triples: {len(graph)}\")\n",
        "\n",
        "# Print numbers of instances\n",
        "instances = set()\n",
        "for s, p, o in graph:\n",
        "    instances.add(s)\n",
        "print(f\"Number of instances: {len(instances)}\") '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gncks7L49Jfh",
        "outputId": "2b30e5fb-18c1-4fd1-e6f9-e63f6e0519f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Execution\\nvalid_categories = [\\'Bauwerk\\', \\'Teilbauwerk\\', \\'Bruecke\\',\\n                   \\'BelagAbdichtung\\', \\'Ausstattungen\\', \\'fhrb_bel.csv\\', \\'Gruendung\\', \\'Kappe\\', \\'Lager\\',\\n                   \\'Leitung\\', \\'Schutzeinrichtungen\\', \\'StatischesSystem_Tragfaehigkeit\\', \\'Vorspannung\\',\\n                   \\'Fahrbahnuebergang\\', \\'Feld\\']\\n\\ngraph = json_rdf_converter(df_SPO, valid_categories)\\n\\n\\n# Print numbers of triples\\nprint(f\"Number of triples: {len(graph)}\")\\n\\n# Print numbers of instances\\ninstances = set()\\nfor s, p, o in graph:\\n    instances.add(s)\\nprint(f\"Number of instances: {len(instances)}\") '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Graph Merging"
      ],
      "metadata": {
        "id": "ai2P0fHEnWh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_mapper(instance_graph_data, mapping_file):\n",
        "    \"\"\"\n",
        "    Links IFC instances to ASB properties using SPARQL queries.\n",
        "\n",
        "    Args:\n",
        "        instance_graph_data (str or rdflib.Graph): Path to the instance graph\n",
        "                                                 file in Turtle format or an\n",
        "                                                 rdflib.Graph object.\n",
        "        mapping_file (str): Path to the mapping Excel file.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create graph and get namespaces\n",
        "    g, ns = create_and_bind_graph()\n",
        "\n",
        "    # Load instance graph\n",
        "    if isinstance(instance_graph_data, str):\n",
        "        # Input is a file path, parse the TTL file\n",
        "        g.parse(instance_graph_data, format='turtle')\n",
        "    elif isinstance(instance_graph_data, Graph):\n",
        "        # Input is an rdflib.Graph object, use it directly\n",
        "        g = instance_graph_data\n",
        "    else:\n",
        "        raise TypeError(\"Invalid input type. Expected str (file path) or rdflib.Graph object.\")\n",
        "\n",
        "    # Load mapping file\n",
        "    mappings = pd.read_excel(mapping_file, sheet_name=\"instance-alignment\")\n",
        "\n",
        "    # Process mappings\n",
        "    for _, row in mappings.iterrows():\n",
        "        # Skip if either field is empty or NaN\n",
        "        if pd.isna(row.ifc_instance_id) or pd.isna(row.asb_instance_id):\n",
        "            continue\n",
        "\n",
        "        # Split and clean IFC instances\n",
        "        ifc_instances = [inst.strip() for inst in str(row.ifc_instance_id).split(',') if inst.strip()]\n",
        "\n",
        "        # Split and clean ASB instances\n",
        "        asb_instances = [inst.strip() for inst in str(row.asb_instance_id).split(',') if inst.strip()]\n",
        "\n",
        "        # Create mappings between all combinations of IFC and ASB instances\n",
        "        for ifc_instance in ifc_instances:\n",
        "            # Skip empty IFC instances\n",
        "            if not ifc_instance:\n",
        "                continue\n",
        "\n",
        "            # Create SPARQL query for each IFC instance\n",
        "            for asb_instance in asb_instances:\n",
        "                # Skip empty ASB instances\n",
        "                if not asb_instance:\n",
        "                    continue\n",
        "\n",
        "                # Create and execute SPARQL query for each combination\n",
        "                query = f\"\"\"\n",
        "                CONSTRUCT {{\n",
        "                    ?inst <{ns['INST']}hasAsbPset> <{ns['ASB']}{asb_instance}>\n",
        "                }}\n",
        "                WHERE {{\n",
        "                    ?inst a ?type .\n",
        "                    FILTER(STRENDS(STR(?inst), \"{ifc_instance}\"))\n",
        "                }}\n",
        "                \"\"\"\n",
        "\n",
        "                # Execute query and add results to graph\n",
        "                results = g.query(query)\n",
        "                for triple in results:\n",
        "                    g.add(triple)\n",
        "\n",
        "    # Add inst:hasAsbPset a owl:ObjectProperty\n",
        "    g.add((ns['INST']['hasAsbPset'], RDF.type, ns['OWL'].ObjectProperty))\n",
        "\n",
        "    # Serialize the graph to the default output file\n",
        "    # output_file = os.path.join(\"output\", \"mapped_graph.ttl\")  # Default output path\n",
        "    # g.serialize(format='turtle', destination=output_file)\n",
        "    print(f\"Mapped graph created with {len(g)} triples\")\n",
        "\n",
        "    return g\n",
        "\n",
        "# Usage\n",
        "# mapped_graph = graph_mapper(\"/content/output/ifc_graph.ttl\", \"/content/data/mapping.xlsx\")"
      ],
      "metadata": {
        "id": "9hBgrevqnZTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph\n",
        "\n",
        "def graphs_merger(input_graphs: list, output_file: str = None):\n",
        "    \"\"\"\n",
        "    Merges multiple RDF graphs into a single graph.\n",
        "\n",
        "    Args:\n",
        "        input_graphs (list): A list of file paths (str) or Graph objects.\n",
        "        output_file (str, optional): Path to save the merged graph. Defaults to None.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a new graph for the merged content\n",
        "    merged_graph = Graph()\n",
        "\n",
        "    for input_graph in input_graphs:\n",
        "        if isinstance(input_graph, str):\n",
        "            # Input is a file path\n",
        "            try:\n",
        "                graph = Graph()  # Create a temporary graph to load the file\n",
        "                graph.parse(input_graph, format=\"turtle\")\n",
        "                merged_graph += graph\n",
        "                print(f\"Loaded {len(graph)} triples from {input_graph}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {input_graph}: {e}\")\n",
        "        elif isinstance(input_graph, Graph):\n",
        "            # Input is a Graph object\n",
        "            merged_graph += input_graph\n",
        "            print(f\"Loaded {len(input_graph)} triples.\")\n",
        "        else:\n",
        "            print(f\"Skipping invalid input: {input_graph}\")\n",
        "\n",
        "    # Copy all namespace bindings from all graphs\n",
        "    for input_graph in input_graphs:\n",
        "        if isinstance(input_graph, Graph):\n",
        "            for prefix, namespace in input_graph.namespaces():\n",
        "                if prefix not in merged_graph.namespaces():\n",
        "                    merged_graph.bind(prefix, namespace)\n",
        "        elif isinstance(input_graph, str):\n",
        "            graph = Graph()\n",
        "            try:\n",
        "                graph.parse(input_graph, format=\"turtle\")\n",
        "                for prefix, namespace in graph.namespaces():\n",
        "                    if prefix not in merged_graph.namespaces():\n",
        "                        merged_graph.bind(prefix, namespace)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading namespaces from {input_graph}: {e}\")\n",
        "\n",
        "    # Serialize the graph to the default output file\n",
        "    output_file = os.path.join(\"output\", \"merged_graph.ttl\")  # Default output path\n",
        "    merged_graph.serialize(format='turtle', destination=output_file)\n",
        "    print(f\"{output_file} created and saved with  {len(merged_graph)} triples .\")\n",
        "\n",
        "    return merged_graph"
      ],
      "metadata": {
        "id": "w5vaeIQeSa_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ontology Linking"
      ],
      "metadata": {
        "id": "aMRfEzxLnaHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def onto_mapper(instance_graph_data, mapping_csv):\n",
        "    \"\"\"\n",
        "    Links an IFC instance graph with external ontologies using mapping definitions.\n",
        "\n",
        "    Args:\n",
        "        instance_graph_path (str): Path to the instance graph file in Turtle format\n",
        "        mapping_csv (str): Path to the mapping Excel file\n",
        "\n",
        "    Returns:\n",
        "        rdflib.Graph: The enriched graph with ontology linkages\n",
        "    \"\"\"\n",
        "    # Create graph and get namespaces\n",
        "    g, ns = create_and_bind_graph()\n",
        "\n",
        "    # Load instance data\n",
        "    if isinstance(instance_graph_data, str):\n",
        "        # Input is a file path, parse the Turtle file\n",
        "        g.parse(instance_graph_data, format='turtle')\n",
        "    elif isinstance(instance_graph_data, Graph):\n",
        "        # Input is an rdflib.Graph object, use it directly\n",
        "        g = instance_graph_data\n",
        "    else:\n",
        "        raise TypeError(\"Invalid input type. Expected str (file path) or rdflib.Graph object.\")\n",
        "\n",
        "    # Load mapping file\n",
        "    mappings = pd.read_excel(mapping_csv, sheet_name=\"instance-alignment\")\n",
        "\n",
        "    # Process each mapping row\n",
        "    for _, row in mappings.iterrows():\n",
        "        # We only proceed if IFC class, ontology prefix, and ontology class are present\n",
        "        if pd.notna(row.ifc_class) and pd.notna(row.ontology_prefix) and pd.notna(row.ontology_class):\n",
        "            # Build SPARQL update to map the IFC class to the ontology class\n",
        "            query = f\"\"\"\n",
        "            INSERT {{\n",
        "                bsdd:{row.ifc_class} owl:equivalentClass {row.ontology_prefix}:{row.ontology_class} .\n",
        "            }}\n",
        "            WHERE {{}}\n",
        "            \"\"\"\n",
        "            g.update(query)\n",
        "        else:\n",
        "            print(f\"Skipping row due to missing values: {row}\")\n",
        "\n",
        "    print(f\"\\nMapped Onto graph created with {len(g)} triples\")\n",
        "    return g\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# linked_graph = onto_mapper(\"/content/output/merged_graph.ttl\", \"/content/data/mapping.xlsx\")"
      ],
      "metadata": {
        "id": "0JorUkNKnccj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def onto_linker(graph_data, ontology_urls=None):\n",
        "    \"\"\"\n",
        "    Links an RDF graph with external ontologies specified in `ontology_urls`.\n",
        "\n",
        "    Args:\n",
        "        graph_data (str or rdflib.Graph): Path to the RDF graph file (Turtle format)\n",
        "                                        or an rdflib.Graph object.\n",
        "        ontology_urls (list, optional): List of URLs to external ontologies. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        rdflib.Graph: The linked RDF graph.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create graph and get namespaces\n",
        "    g, ns = create_and_bind_graph()\n",
        "\n",
        "    # Load the main graph\n",
        "    if isinstance(graph_data, str):\n",
        "        # Input is a file path, parse the Turtle file\n",
        "        g.parse(graph_data, format=\"turtle\")\n",
        "    elif isinstance(graph_data, Graph):\n",
        "        # Input is an rdflib.Graph object, use it directly\n",
        "        g = graph_data\n",
        "    else:\n",
        "        raise TypeError(\"Invalid input type for graph_data. Expected str (file path) or rdflib.Graph object.\")\n",
        "\n",
        "\n",
        "    # Stop if ontology_urls is None\n",
        "    if ontology_urls is None:\n",
        "        print(\"No ontology URLs provided. Stopping execution.\")\n",
        "        return g  # Return the graph as is without linking\n",
        "\n",
        "    # Load each ontology\n",
        "    for url in ontology_urls:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
        "            g.parse(data=response.text, format=\"turtle\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Failed to load ontology from {url}. Error: {str(e)}\")\n",
        "\n",
        "    # Serialize the graph to the default output file\n",
        "    output_file = os.path.join(\"output\", \"linked_graph.ttl\")  # Default output path\n",
        "    g.serialize(format='turtle', destination=output_file)\n",
        "    print(f\"{output_file}h created and saved with {len(g)} triples\")\n",
        "\n",
        "    return g\n",
        "\n",
        "'''\n",
        "# Example usage\n",
        "custom_urls = [\"https://example.com/ontology1.ttl\",\n",
        "               \"https://example.com/ontology2.ttl\"\n",
        "               ]\n",
        "g = onto_linker(\"ifc_linked.ttl\", custom_urls)'''"
      ],
      "metadata": {
        "id": "lLwccQsqnFH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8d0c5f-e545-44f8-e17a-33133c112574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example usage\\ncustom_urls = [\"https://example.com/ontology1.ttl\",\\n               \"https://example.com/ontology2.ttl\"\\n               ]\\ng = onto_linker(\"ifc_linked.ttl\", custom_urls)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Graph Completion"
      ],
      "metadata": {
        "id": "TWRyUsZfnejJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph\n",
        "from owlrl import DeductiveClosure, OWLRL_Semantics\n",
        "\n",
        "def basic_reasoner(graph_path, output_path):\n",
        "    \"\"\"\n",
        "    Performs OWL 2 RL reasoning on an RDF graph using owlrl.\n",
        "\n",
        "    Args:\n",
        "        graph_path (str): Path to the input RDF graph file (Turtle format).\n",
        "        output_path (str): Path to save the inferred graph (Turtle format).\n",
        "    \"\"\"\n",
        "    # Load the graph\n",
        "    g = Graph()\n",
        "    g.parse(graph_path, format=\"turtle\")\n",
        "\n",
        "    # Create a deductive closure object\n",
        "    dc = DeductiveClosure(OWLRL_Semantics)\n",
        "\n",
        "    # Expand the graph with inferences\n",
        "    dc.expand(g)\n",
        "\n",
        "    # Save the inferred graph\n",
        "    g.serialize(destination=output_path, format=\"turtle\")\n",
        "\n",
        "    print(f\"Inferred graph saved to: {output_path}\")\n",
        "    print(f\"Total triples after inference: {len(g)}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# graph_path = \"/content/output/linked_graph.ttl\"  # Path to your input graph\n",
        "# output_path = \"/content/output/inferred_graph.ttl\"  # Path to save the inferred graph\n",
        "# basic_reasoner(graph_path, output_path)"
      ],
      "metadata": {
        "id": "X81KMh0Wnpci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "df0-clDk_KhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisation"
      ],
      "metadata": {
        "id": "tt57iN8ncQKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph, URIRef, BNode, Literal\n",
        "from pyvis.network import Network\n",
        "import colorsys\n",
        "import hashlib\n",
        "\n",
        "def visualize_rdf(input_data, output_html=\"graph.html\", custom_options=None):\n",
        "    \"\"\"\n",
        "    RDF graph visualization with interactive features.\n",
        "\n",
        "    Parameters:\n",
        "    input_data (str or Graph): Path to TTL file or rdflib.Graph object\n",
        "    output_html (str): Path to save the generated HTML file\n",
        "    custom_options (dict): Optional custom vis.js options to override defaults\n",
        "    \"\"\"\n",
        "    # Initialize RDF Graph\n",
        "    g = Graph()\n",
        "\n",
        "    # Check input type and load data accordingly\n",
        "    if isinstance(input_data, str):\n",
        "        g.parse(input_data, format='turtle')\n",
        "    elif isinstance(input_data, Graph):\n",
        "        g = input_data\n",
        "    else:\n",
        "        raise TypeError(\"Invalid input type. Expected str (file path) or rdflib.Graph object.\")\n",
        "\n",
        "    # Generate consistent, visually pleasing colors for namespaces\n",
        "    def generate_color(prefix, saturation=0.7, value=0.95):\n",
        "        \"\"\"Generate consistent, color for a prefix\"\"\"\n",
        "        hash_value = int(hashlib.md5(prefix.encode('utf-8')).hexdigest(), 16)\n",
        "        hue = hash_value % 360 / 360.0\n",
        "        rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
        "        return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))\n",
        "\n",
        "    # Extract namespace prefixes and assign colors\n",
        "    namespace_colors = {}\n",
        "    prefix_color_mapping = {\n",
        "        'inst': '#1E3A8A',    # Deep blue\n",
        "        'asb': '#BE123C',     # Rich red\n",
        "        'bsdd': '#065F46',    # Forest green\n",
        "        'prop': '#047857',    # Emerald green\n",
        "        'rdf': '#7E22CE',     # Purple\n",
        "        'rdfs': '#6D28D9',    # Indigo\n",
        "        'owl': '#8B5CF6',     # Violet\n",
        "        'xsd': '#0284C7',     # Sky blue\n",
        "    }\n",
        "\n",
        "    # Assign colors based on prefix or generate new ones\n",
        "    for prefix, namespace in g.namespaces():\n",
        "        if prefix in prefix_color_mapping:\n",
        "            namespace_colors[str(namespace)] = prefix_color_mapping[prefix]\n",
        "        else:\n",
        "            namespace_colors[str(namespace)] = generate_color(prefix)\n",
        "\n",
        "    # Enhanced node and edge styling\n",
        "    node_styles = {\n",
        "        \"URIRef\": {\n",
        "            \"shape\": \"dot\",\n",
        "            \"size\": 20,\n",
        "            \"font\": {\"size\": 16, \"face\": \"Helvetica\", \"strokeWidth\": 0, \"color\": \"#333333\"},\n",
        "            \"shadow\": {\"enabled\": True, \"size\": 5, \"x\": 3, \"y\": 3, \"color\": \"rgba(0,0,0,0.2)\"}\n",
        "        },\n",
        "        \"BNode\": {\n",
        "            \"shape\": \"hexagon\",\n",
        "            \"size\": 15,\n",
        "            \"color\": \"#9CA3AF\",\n",
        "            \"font\": {\"size\": 14, \"face\": \"Helvetica\", \"color\": \"#4B5563\"}\n",
        "        },\n",
        "        \"Literal\": {\n",
        "            \"shape\": \"box\",\n",
        "            \"size\": 10,\n",
        "            \"color\": \"#D1D5DB\",\n",
        "            \"font\": {\"size\": 14, \"face\": \"Helvetica\", \"color\": \"#1F2937\"}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Create collections for nodes and edges\n",
        "    nodes = {}\n",
        "    edges = []\n",
        "\n",
        "    # Process triples to extract nodes and edges\n",
        "    for s, p, o in g:\n",
        "        # Handle subject node\n",
        "        s_id = str(s)\n",
        "        s_namespace = next((ns for ns in namespace_colors if s_id.startswith(ns)), None)\n",
        "\n",
        "        if isinstance(s, URIRef):\n",
        "            # For URIs, use the last segment as the label\n",
        "            s_label = s_id.split('/')[-1].split('#')[-1]\n",
        "            s_type = \"URIRef\"\n",
        "            s_color = namespace_colors.get(s_namespace, generate_color(s_id))\n",
        "        elif isinstance(s, BNode):\n",
        "            s_label = f\"_:{s_id[-4:]}\"  # Shortened blank node label\n",
        "            s_type = \"BNode\"\n",
        "            s_color = node_styles[\"BNode\"][\"color\"]\n",
        "        else:\n",
        "            s_label = str(s)[:30] + (\"...\" if len(str(s)) > 30 else \"\")\n",
        "            s_type = \"Literal\"\n",
        "            s_color = node_styles[\"Literal\"][\"color\"]\n",
        "\n",
        "        nodes[s_id] = {\n",
        "            \"label\": s_label,\n",
        "            \"title\": s_id,  # Full URI on hover\n",
        "            \"type\": s_type,\n",
        "            \"color\": s_color,\n",
        "            **node_styles[s_type]\n",
        "        }\n",
        "\n",
        "        # Handle object node with similar logic\n",
        "        o_id = str(o)\n",
        "        o_namespace = next((ns for ns in namespace_colors if o_id.startswith(ns)), None)\n",
        "\n",
        "        if isinstance(o, URIRef):\n",
        "            o_label = o_id.split('/')[-1].split('#')[-1]\n",
        "            o_type = \"URIRef\"\n",
        "            o_color = namespace_colors.get(o_namespace, generate_color(o_id))\n",
        "        elif isinstance(o, BNode):\n",
        "            o_label = f\"_:{o_id[-4:]}\"\n",
        "            o_type = \"BNode\"\n",
        "            o_color = node_styles[\"BNode\"][\"color\"]\n",
        "        elif isinstance(o, Literal):\n",
        "            # Truncate long literals\n",
        "            o_value = str(o)\n",
        "            o_label = (o_value[:30] + \"...\") if len(o_value) > 30 else o_value\n",
        "            o_type = \"Literal\"\n",
        "            o_color = node_styles[\"Literal\"][\"color\"]\n",
        "        else:\n",
        "            o_label = str(o)[:30] + (\"...\" if len(str(o)) > 30 else \"\")\n",
        "            o_type = \"Literal\"\n",
        "            o_color = node_styles[\"Literal\"][\"color\"]\n",
        "\n",
        "        nodes[o_id] = {\n",
        "            \"label\": o_label,\n",
        "            \"title\": o_id,  # Full value on hover\n",
        "            \"type\": o_type,\n",
        "            \"color\": o_color,\n",
        "            **node_styles[o_type]\n",
        "        }\n",
        "\n",
        "        # Handle predicate (relationship)\n",
        "        p_id = str(p)\n",
        "        p_label = p_id.split('/')[-1].split('#')[-1]\n",
        "\n",
        "        # Add edge\n",
        "        edges.append({\n",
        "            \"from\": s_id,\n",
        "            \"to\": o_id,\n",
        "            \"label\": p_label,\n",
        "            \"title\": p_id,  # Full predicate URI on hover\n",
        "            \"font\": {\"size\": 12, \"align\": \"middle\", \"background\": \"white\"},\n",
        "            \"color\": {\"color\": \"#64748B\", \"opacity\": 0.8},\n",
        "            \"smooth\": {\"type\": \"curvedCW\", \"roundness\": 0.2},\n",
        "            \"arrows\": {\"to\": {\"enabled\": True, \"scaleFactor\": 0.5}}\n",
        "        })\n",
        "\n",
        "    # Create network with better defaults\n",
        "    net = Network(\n",
        "        height=\"850px\",\n",
        "        width=\"100%\",\n",
        "        bgcolor=\"#FFFFFF\",  # White background\n",
        "        font_color=\"#1F2937\",\n",
        "        directed=True,\n",
        "        notebook=False,\n",
        "        select_menu=False,\n",
        "        filter_menu=False,\n",
        "        neighborhood_highlight=True,  # Highlight connected nodes on click\n",
        "        cdn_resources=\"remote\"  # Use CDN for better loading\n",
        "    )\n",
        "\n",
        "    # Default heading\n",
        "    net.heading = net.heading = f\"RDF Graph Visualization ({len(nodes)} nodes, {len(edges)} relationships)\"\n",
        "\n",
        "    # Add nodes to network\n",
        "    for node_id, node_data in nodes.items():\n",
        "        style_data = {k: v for k, v in node_data.items() if k not in [\"label\", \"title\", \"type\"]}\n",
        "        net.add_node(\n",
        "            node_id,\n",
        "            label=node_data[\"label\"],\n",
        "            title=node_data[\"title\"],\n",
        "            **style_data\n",
        "        )\n",
        "\n",
        "    # Add edges to network\n",
        "    for edge_data in edges:\n",
        "        net.add_edge(\n",
        "            edge_data[\"from\"],\n",
        "            edge_data[\"to\"],\n",
        "            title=edge_data[\"title\"],\n",
        "            label=edge_data[\"label\"],\n",
        "            **{k: v for k, v in edge_data.items() if k not in [\"from\", \"to\", \"label\", \"title\"]}\n",
        "        )\n",
        "\n",
        "    # Default enhanced physics and interaction options\n",
        "    default_options = {\n",
        "        \"physics\": {\n",
        "            \"enabled\": True,\n",
        "            \"solver\": \"forceAtlas2Based\",\n",
        "            \"forceAtlas2Based\": {\n",
        "                \"gravitationalConstant\": -75,\n",
        "                \"centralGravity\": 0.01,\n",
        "                \"springLength\": 150,\n",
        "                \"springConstant\": 0.05,\n",
        "                \"damping\": 0.09\n",
        "            },\n",
        "            \"minVelocity\": 0.75,\n",
        "            \"stabilization\": {\n",
        "                \"enabled\": True,\n",
        "                \"iterations\": 100,\n",
        "                \"updateInterval\": 10\n",
        "            }\n",
        "        },\n",
        "        \"layout\": {\n",
        "            \"randomSeed\": 42,\n",
        "            \"improvedLayout\": True\n",
        "        },\n",
        "        \"interaction\": {\n",
        "            \"hover\": True,\n",
        "            \"hoverConnectedEdges\": True,\n",
        "            \"selectConnectedEdges\": True,\n",
        "            \"multiselect\": True,\n",
        "            \"dragNodes\": True,\n",
        "            \"hideEdgesOnDrag\": False,\n",
        "            \"hideNodesOnDrag\": False,\n",
        "            \"navigationButtons\": True,\n",
        "            \"keyboard\": {\n",
        "                \"enabled\": True,\n",
        "                \"speed\": {\"x\": 10, \"y\": 10, \"zoom\": 0.1}\n",
        "            },\n",
        "            \"zoomView\": True\n",
        "        },\n",
        "        \"edges\": {\n",
        "            \"smooth\": {\"type\": \"dynamic\"},\n",
        "            \"length\": 250,\n",
        "            \"color\": {\"inherit\": \"both\"},\n",
        "            \"selectionWidth\": 3\n",
        "        },\n",
        "        \"groups\": {\n",
        "            # Add namespace-based groups for legend\n",
        "            **{prefix: {\"color\": color} for prefix, color in prefix_color_mapping.items()}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Merge with any custom options provided\n",
        "    if custom_options:\n",
        "        # Helper function to recursively merge dictionaries\n",
        "        def deep_merge(d1, d2):\n",
        "            for k in d2:\n",
        "                if k in d1 and isinstance(d1[k], dict) and isinstance(d2[k], dict):\n",
        "                    deep_merge(d1[k], d2[k])\n",
        "                else:\n",
        "                    d1[k] = d2[k]\n",
        "            return d1\n",
        "\n",
        "        options = deep_merge(default_options, custom_options)\n",
        "    else:\n",
        "        options = default_options\n",
        "\n",
        "    # Apply options to network\n",
        "    net.set_options(json.dumps(options))\n",
        "\n",
        "    # Add legend with HTML\n",
        "    legend_html = \"\"\"\n",
        "    <div style=\"position: absolute; top: 10px; right: 10px; background: rgba(255, 255, 255, 0.8);\n",
        "                padding: 10px; border-radius: 5px; border: 1px solid #ddd; z-index: 100; max-width: 250px;\">\n",
        "        <h3 style=\"margin-top: 0; font-family: Helvetica;\">Legend</h3>\n",
        "        <div style=\"display: flex; flex-direction: column; gap: 5px;\">\n",
        "    \"\"\"\n",
        "\n",
        "    # Add legend items for node types\n",
        "    legend_html += f\"\"\"\n",
        "        <div style=\"display: flex; align-items: center; gap: 5px;\">\n",
        "            <div style=\"width: 15px; height: 15px; border-radius: 50%; background: {node_styles['URIRef']['color'] if 'color' in node_styles['URIRef'] else '#1E3A8A'};\"></div>\n",
        "            <span style=\"font-family: Helvetica; font-size: 12px;\">URI Reference</span>\n",
        "        </div>\n",
        "        <div style=\"display: flex; align-items: center; gap: 5px;\">\n",
        "            <div style=\"width: 15px; height: 15px; background: {node_styles['BNode']['color']}; clip-path: polygon(50% 0%, 100% 25%, 100% 75%, 50% 100%, 0% 75%, 0% 25%);\"></div>\n",
        "            <span style=\"font-family: Helvetica; font-size: 12px;\">Blank Node</span>\n",
        "        </div>\n",
        "        <div style=\"display: flex; align-items: center; gap: 5px;\">\n",
        "            <div style=\"width: 15px; height: 15px; background: {node_styles['Literal']['color']}; border-radius: 2px;\"></div>\n",
        "            <span style=\"font-family: Helvetica; font-size: 12px;\">Literal</span>\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add namespace prefixes to legend\n",
        "    legend_html += \"<h4 style='margin-bottom: 5px; font-family: Helvetica; font-size: 14px;'>Namespaces</h4>\"\n",
        "    for prefix, color in prefix_color_mapping.items():\n",
        "        legend_html += f\"\"\"\n",
        "            <div style=\"display: flex; align-items: center; gap: 5px;\">\n",
        "                <div style=\"width: 15px; height: 15px; border-radius: 50%; background: {color};\"></div>\n",
        "                <span style=\"font-family: Helvetica; font-size: 12px;\">{prefix}</span>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "\n",
        "    legend_html += \"\"\"\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add controls help tooltip\n",
        "    controls_html = \"\"\"\n",
        "    <div style=\"position: absolute; bottom: 10px; left: 10px; background: rgba(255, 255, 255, 0.8);\n",
        "                padding: 10px; border-radius: 5px; border: 1px solid #ddd; z-index: 100; font-family: Helvetica;\">\n",
        "        <h3 style=\"margin-top: 0; font-size: 14px;\">Controls</h3>\n",
        "        <ul style=\"margin: 0; padding-left: 20px; font-size: 12px;\">\n",
        "            <li>Click node to highlight connections</li>\n",
        "            <li>Drag to move nodes</li>\n",
        "            <li>Scroll to zoom</li>\n",
        "            <li>Hold Ctrl to select multiple nodes</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Inject custom HTML into the generated file\n",
        "    net.html = net.html.replace(\"</body>\", f\"{legend_html}{controls_html}</body>\")\n",
        "\n",
        "    # Save the graph\n",
        "    net.save_graph(output_html)\n",
        "    print(f\"Visualization saved as {output_html}\")\n",
        "\n",
        "    return net\n",
        "\n",
        "'''\n",
        "# Example of how to use with custom options:\n",
        "custom_options = {\n",
        "    \"physics\": {\n",
        "        \"forceAtlas2Based\": {\"improvedLayout\": True}\n",
        "        },\n",
        "    \"layout\": {\"circular\": {\"scale\": 300}}\n",
        "     }\n",
        "visualize_rdf(\"/content/output/ifc_graph.ttl\", \"/content/output/ifc_graph.html\", custom_options)'''\n",
        "\n"
      ],
      "metadata": {
        "id": "mrP90qv4JWA4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a68207ce-13d3-4125-899f-f3a98a8fdabd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example of how to use with custom options:\\ncustom_options = {\\n    \"physics\": {\\n        \"forceAtlas2Based\": {\"improvedLayout\": True}\\n        },\\n    \"layout\": {\"circular\": {\"scale\": 300}}\\n     }\\nvisualize_rdf(\"/content/output/ifc_graph.ttl\", \"/content/output/ifc_graph.html\", custom_options)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution\n",
        "\n",
        "This is the main execution section of the pipeline to realize all the functions above."
      ],
      "metadata": {
        "id": "00bxZW_b-ypk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' IFC to RDF conversion '''\n",
        "\n",
        "# Input Data\n",
        "ifc_file = \"/content/data/UKA_UK_Aachen_IFC_02.ifc\"\n",
        "\n",
        "# Process IFC and generate IFC Graph\n",
        "ifc_attr = ifc_extractor(ifc_file)  # optional\n",
        "ifc_graph = ifc_rdf_converter(ifc_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLV3TM-RxTC5",
        "outputId": "f8327f08-3a84-4257-f395-e6ad72ebc625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output/ifc_attributes.csv created and saved with 41 attributes\n",
            "output/ifc_graph.ttl created and saved with 202 triples\n",
            "Number of relationships: 81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' JSON/ASB data preprocessing and conversion to RDF '''\n",
        "\n",
        "# Input Data\n",
        "json_file = \"/content/data/extracted_B115.json\"\n",
        "mapping_table = \"/content/data/mapping.xlsx\"\n",
        "valid_categories = ['Bauwerk', 'Teilbauwerk', 'Bruecke',\n",
        "                   'BelagAbdichtung', 'Ausstattungen', 'fhrb_bel.csv', 'Gruendung', 'Kappe', 'Lager',\n",
        "                   'Leitung', 'Schutzeinrichtungen', 'StatischesSystem_Tragfaehigkeit', 'Vorspannung',\n",
        "                   'Fahrbahnuebergang', 'Feld']\n",
        "\n",
        "\n",
        "# Process JSON/ASB data, create SPO and generate ASB Graph\n",
        "asb_df = main_spo_extractor(json_file,mapping_table)\n",
        "asb_graph = json_rdf_converter(asb_df, valid_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2QAXIF-xiEL",
        "outputId": "222984b3-0f67-444c-97ff-acd06d1ff272",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Statistics Key-Value Map:\n",
            "Total 15-digit values processed: 5776\n",
            "Matches found: 5018\n",
            "Number of files processed: 62\n",
            "\n",
            "Total rows in SPO: 29464 \n",
            "\n",
            "output/asb_graph.ttl created and saved with 554 triples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Map and Merge instance graphs (IFC and ASB) '''\n",
        "\n",
        "# Map IFC instances and ASB instances\n",
        "mapped_graph = graph_mapper(ifc_graph, mapping_table)\n",
        "\n",
        "# Input Data\n",
        "input_graphs = [mapped_graph, asb_graph] # add more graphs as needed\n",
        "\n",
        "# Merge instance graphs and generate a new graph\n",
        "merged_graph = graphs_merger(input_graphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6kdmRbUf-z_",
        "outputId": "c80808d9-600e-4d53-d6f4-49a70866aa96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped graph created with 242 triples\n",
            "Loaded 242 triples.\n",
            "Loaded 554 triples.\n",
            "output/merged_graph.ttl created and saved with  796 triples .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Map and Link merged graph with ontologies '''\n",
        "\n",
        "# Map IFC classes and Ontology concepts\n",
        "mapped_onto_graph = onto_mapper(merged_graph, mapping_table)\n",
        "\n",
        "# Input Data\n",
        "onto_urls = [\"https://alhakam.github.io/brcomp/ontology.ttl\",\n",
        "            \"https://alhakam.github.io/brot/ontology.ttl\"\n",
        "               ] # add more links as needed\n",
        "\n",
        "# Link merge graphs and ontology classes and generate a new linked graph\n",
        "linked_graph = onto_linker(mapped_onto_graph, onto_urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezI_C2MEYc0l",
        "outputId": "394e0c06-de5d-4b3d-cd2a-b289864f0a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mapped Onto graph created with 806 triples\n",
            "output/linked_graph.ttlh created and saved with 1340 triples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Apply basic reasoning by OWL 2 RL '''\n",
        "\n",
        "graph_path = \"/content/output/linked_graph.ttl\"  # Path to input graph\n",
        "output_path = \"/content/output/enriched_graph.ttl\"  # Path to save the inferred graph\n",
        "\n",
        "# Function to generate enriched graph from linked graph\n",
        "basic_reasoner(graph_path, output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEqvbWWpnyO2",
        "outputId": "382209dc-9057-4c10-fc34-639f6e6bf9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred graph saved to: /content/output/enriched_graph.ttl\n",
            "Total triples after inference: 3230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualisation\n",
        "custom_options = {\n",
        "    \"physics\": {\n",
        "        \"forceAtlas2Based\": {\"improvedLayout\": True}\n",
        "        },\n",
        "    \"layout\": {\"circular\": {\"scale\": 300}}\n",
        "     }\n",
        "visualize_rdf(\"/content/output/ifc_graph.ttl\", \"/content/output/ifc_graph.html\", custom_options)\n",
        "visualize_rdf(\"/content/output/asb_graph.ttl\", \"/content/output/asb_graph.html\", custom_options)\n",
        "visualize_rdf(\"/content/output/merged_graph.ttl\", \"/content/output/merged_graph.html\", custom_options)\n",
        "visualize_rdf(\"/content/output/linked_graph.ttl\", \"/content/output/linked_graph.html\", custom_options)\n",
        "visualize_rdf(\"/content/output/enriched_graph.ttl\", \"/content/output/enriched_graph.html\", custom_options)"
      ],
      "metadata": {
        "id": "7lzBX1Lttn-W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dc128d0d-587b-48dc-dce6-276ccfbfc9e9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization saved as /content/output/ifc_graph.html\n",
            "Visualization saved as /content/output/asb_graph.html\n",
            "Visualization saved as /content/output/merged_graph.html\n",
            "Visualization saved as /content/output/linked_graph.html\n",
            "Visualization saved as /content/output/enriched_graph.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'pyvis.network.Network'> |N|=993 |E|=3,230"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Querying and Validation"
      ],
      "metadata": {
        "id": "W9U2UJsvhPFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Querying instance graphs"
      ],
      "metadata": {
        "id": "Nb2rr9HGhZ5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Which object types are contained in a specific spatial container? '''\n",
        "\n",
        "# Load the RDF graph\n",
        "ifc_graph = Graph()\n",
        "ifc_graph.parse(\"/content/output/ifc_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Query the graph\n",
        "query = \"\"\"\n",
        "PREFIX bsdd: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/>\n",
        "PREFIX inst: <http://ifc-instance.org/instances/>\n",
        "PREFIX prop: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/prop/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "\n",
        "SELECT ?subj ?subjType ?obj ?objType\n",
        "WHERE {\n",
        "    ?subj inst:IfcRelContainedInSpatialStructure ?obj .\n",
        "    ?subj a ?subjType .\n",
        "    ?obj a ?objType .\n",
        "} GROUP BY ?objType\n",
        "\"\"\"\n",
        "\n",
        "results = ifc_graph.query(query)\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(f\"{row.subjType} contains {row.objType}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xAaMnoaG1MK",
        "outputId": "6f074f61-2d40-473a-e763-a7225551540e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgeGIRDER contains https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcRailing\n",
            "https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgeGIRDER contains https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartDECK\n",
            "https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgeGIRDER contains https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER\n",
            "https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgeGIRDER contains https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartFOUNDATION\n",
            "https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgeGIRDER contains https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartABUTMENT\n",
            "https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgeGIRDER contains https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Extract the ids of elements that are instances of IFC type IfcBridgePartABUTMENT . '''\n",
        "\n",
        "# Load the RDF graph\n",
        "ifc_graph = Graph()\n",
        "ifc_graph.parse(\"/content/output/ifc_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Query the graph\n",
        "query = \"\"\"\n",
        "PREFIX bsdd: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/>\n",
        "PREFIX inst: <http://ifc-instance.org/instances/>\n",
        "PREFIX prop: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/prop/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "\n",
        "SELECT ?element ?name\n",
        "WHERE {\n",
        "    ?element a bsdd:IfcBridgePartABUTMENT .\n",
        "    ?element rdfs:label ?name .\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "results = ifc_graph.query(query)\n",
        "\n",
        "# Print the results\n",
        "print(\"Elements that are instances of IfcBridgePartABUTMENT:\")\n",
        "for row in results:\n",
        "    print(f\"{row.element}: {row.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lHQRwdwhpbo",
        "outputId": "cad96d03-4aa3-48a1-c328-3755f3cfd4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements that are instances of IfcBridgePartABUTMENT:\n",
            "http://ifc-instance.org/instances/43395: Widerlager_Ost:Widerlager_Ost:2618100\n",
            "http://ifc-instance.org/instances/43741: Widerlager_West:Widerlager_West:2656902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Query asb graph to extract numbers of associated elements for each ASB property set. Here bridge support structures. '''\n",
        "\n",
        "# Load the RDF graph\n",
        "asb_graph = Graph()\n",
        "asb_graph.parse(\"/content/output/asb_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Query the graph\n",
        "query = \"\"\"\n",
        "PREFIX asb: <http://asb-example.org/>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "\n",
        "SELECT ?pset ?elements WHERE {\n",
        "    ?pset a asb:ASB_Pset_Feld .\n",
        "    ?pset asb:ANZAHL_ST ?elements .\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "results = asb_graph.query(query)\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(f\"Pset {row.pset} is associated with {row.elements} bridge components.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XcPs2mB_mSdz",
        "outputId": "030b6ce4-b98d-4623-d91d-882f41ae8910"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pset http://asb-example.org/4B0W1WZO is associated with 1 bridge components.\n",
            "Pset http://asb-example.org/4B0W1WZP is associated with 3 bridge components.\n",
            "Pset http://asb-example.org/4B0W1WZQ is associated with 3 bridge components.\n",
            "Pset http://asb-example.org/4B0W1WZR is associated with 1 bridge components.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Querying merged graph"
      ],
      "metadata": {
        "id": "X6CpsW5nhp0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Extract associated ASB pset of IfcBridgePartABUTMENT and IfcBridgePartPIER .'''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/merged_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query = \"\"\"\n",
        "PREFIX asb: <http://asb-example.org/>\n",
        "PREFIX bsdd: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/>\n",
        "PREFIX inst: <http://ifc-instance.org/instances/>\n",
        "PREFIX prop: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/prop/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "\n",
        "SELECT ?ifcInst ?ifcClass ?psetInstance ?psetClass ?property ?value\n",
        "WHERE {\n",
        "  {?ifcInst a bsdd:IfcBridgePartABUTMENT .} UNION {?ifcInst a bsdd:IfcBridgePartPIER .}\n",
        "  ?ifcInst inst:hasAsbPset ?psetInstance .\n",
        "  ?psetInstance a ?psetClass .\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "results = g.query(query)\n",
        "\n",
        "# Print the results\n",
        "for row in results:\n",
        "    print(f\"IFC Instance: {row.ifcInst} has ASB Pset: {row.psetInstance} .\")\n",
        "    # print(f\"IFC Instance: {row.ifcInst} has ASB Pset: {row.psetInstance} that is of type {row.psetClass}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lexe7bkSBpIt",
        "outputId": "f750b327-54d6-4e25-ffe5-ad19681d2c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFC Instance: http://ifc-instance.org/instances/43395 has ASB Pset: http://asb-example.org/4B0W1WZO .\n",
            "IFC Instance: http://ifc-instance.org/instances/43741 has ASB Pset: http://asb-example.org/4B0W1WZR .\n",
            "IFC Instance: http://ifc-instance.org/instances/42796 has ASB Pset: http://asb-example.org/4B0W1WZP .\n",
            "IFC Instance: http://ifc-instance.org/instances/42819 has ASB Pset: http://asb-example.org/4B0W1WZP .\n",
            "IFC Instance: http://ifc-instance.org/instances/42841 has ASB Pset: http://asb-example.org/4B0W1WZP .\n",
            "IFC Instance: http://ifc-instance.org/instances/42863 has ASB Pset: http://asb-example.org/4B0W1WZQ .\n",
            "IFC Instance: http://ifc-instance.org/instances/42885 has ASB Pset: http://asb-example.org/4B0W1WZQ .\n",
            "IFC Instance: http://ifc-instance.org/instances/42894 has ASB Pset: http://asb-example.org/4B0W1WZQ .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Extract ASB properties of IfcBridgePartAbutment type. '''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/merged_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query_1 = \"\"\"\n",
        "PREFIX inst: <http://ifc-instance.org/instances/>\n",
        "PREFIX asb: <http://asb-example.org/>\n",
        "PREFIX prop: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/prop/>\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "\n",
        "SELECT ?ifcType ?psetInstance ?psetClass ?property ?value\n",
        "WHERE {\n",
        "  ?ifcType a bsdd:IfcBridgePartABUTMENT .\n",
        "  ?ifcType inst:hasAsbPset ?psetInstance .\n",
        "  ?psetInstance a ?psetClass .\n",
        "  ?psetInstance ?property ?value .\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "results = g.query(query_1)\n",
        "\n",
        "# Group results by psetClass and then by psetInstance\n",
        "pset_data = defaultdict(lambda: defaultdict(dict))\n",
        "for row in results:\n",
        "    pset_data[row.psetClass][row.psetInstance][row.property] = row.value\n",
        "\n",
        "# Print the first psetInstance and its values for each psetClass\n",
        "print(\"bsdd:IfcBridgePartABUTMENT has the following properties: \")\n",
        "for psetClass, instances_data in pset_data.items():\n",
        "    print(f\"Pset Category: {psetClass}\")\n",
        "    if instances_data:\n",
        "        first_instance = next(iter(instances_data))  # Get the first psetInstance\n",
        "        print(f\"Pset ID: {first_instance}\")\n",
        "        for property, value in instances_data[first_instance].items():\n",
        "            print(f\"{property}: {value}\")\n",
        "        print()\n",
        "    else:\n",
        "        print(\"No instances found for this psetClass.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NjKuNQSzVNus",
        "outputId": "398283ca-1ec9-44b1-a82f-92720f00ac8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bsdd:IfcBridgePartABUTMENT has the following properties: \n",
            "Pset Category: http://asb-example.org/ASB_Pset_Feld\n",
            "Pset ID: http://asb-example.org/4B0W1WZO\n",
            "http://www.w3.org/1999/02/22-rdf-syntax-ns#type: http://asb-example.org/ASB_Pset_Feld\n",
            "http://asb-example.org/AMT: 533\n",
            "http://asb-example.org/ANZAHL_ST: 1\n",
            "http://asb-example.org/ART: http://asb-example.org/40011100000000\n",
            "http://asb-example.org/BEARBEITER: CODEKERK\n",
            "http://asb-example.org/BEARB_DAT: 2002-08-27T08:34:54.999000\n",
            "http://asb-example.org/BEMERKUNG: Widerlager 1\r\n",
            "***\n",
            "http://asb-example.org/BWNR: http://asb-example.org/B115\n",
            "http://asb-example.org/FELDNR: http://asb-example.org/0\n",
            "http://asb-example.org/FELD_NR: http://asb-example.org/1\n",
            "http://asb-example.org/IDENT: http://asb-example.org/4B0W1WZO\n",
            "http://asb-example.org/ID_NR: http://asb-example.org/B115_0\n",
            "http://asb-example.org/REF_BRUCKE: http://asb-example.org/4B0W1X9V\n",
            "http://asb-example.org/REF_FELDER: http://asb-example.org/4B0W1X9W\n",
            "http://asb-example.org/SCHIFF_OEF: http://asb-example.org/0\n",
            "http://asb-example.org/STUETZ_H: 1.5\n",
            "http://asb-example.org/TEIL_BWNR: http://asb-example.org/0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Querying linked graph"
      ],
      "metadata": {
        "id": "I5bVuJX3hw05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Extract ASB pset of Abutment or Pier. '''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/linked_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query = \"\"\"\n",
        "PREFIX asb: <http://asb-example.org/>\n",
        "PREFIX bsdd: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/>\n",
        "PREFIX inst: <http://ifc-instance.org/instances/>\n",
        "PREFIX prop: <https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/prop/>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX brcomp: <https://w3id.org/brcomp#>\n",
        "PREFIX brot: <https://w3id.org/brot#>\n",
        "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
        "\n",
        "SELECT ?inst ?ifcClass ?pset\n",
        "WHERE {\n",
        "  ?inst inst:hasAsbPset ?pset .\n",
        "  ?inst a ?ifcClass .\n",
        "  {?ifcClass owl:equivalentClass brcomp:Abutment .} UNION {?ifcClass owl:equivalentClass brcomp:Pier .}\n",
        "}\n",
        "\"\"\"\n",
        "# Execute the query\n",
        "results = g.query(query)\n",
        "\n",
        "for row in results:\n",
        "  print(f\"IFC Instance: {row.inst} has ASB Pset: {row.pset}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOwrrx7ABDDI",
        "outputId": "868eb3ed-eb07-4c2c-fa2b-12c0e173cb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFC Instance: http://ifc-instance.org/instances/42796 has ASB Pset: http://asb-example.org/4B0W1WZP.\n",
            "IFC Instance: http://ifc-instance.org/instances/42819 has ASB Pset: http://asb-example.org/4B0W1WZP.\n",
            "IFC Instance: http://ifc-instance.org/instances/42841 has ASB Pset: http://asb-example.org/4B0W1WZP.\n",
            "IFC Instance: http://ifc-instance.org/instances/42863 has ASB Pset: http://asb-example.org/4B0W1WZQ.\n",
            "IFC Instance: http://ifc-instance.org/instances/42885 has ASB Pset: http://asb-example.org/4B0W1WZQ.\n",
            "IFC Instance: http://ifc-instance.org/instances/42894 has ASB Pset: http://asb-example.org/4B0W1WZQ.\n",
            "IFC Instance: http://ifc-instance.org/instances/43395 has ASB Pset: http://asb-example.org/4B0W1WZO.\n",
            "IFC Instance: http://ifc-instance.org/instances/43741 has ASB Pset: http://asb-example.org/4B0W1WZR.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Extract substructure components. The expected result contains Abutment, Pier and Foundations.\n",
        "    But as the linked graph is not yet applied with inferencing engines. Such associations can't be made yet. '''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/linked_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query = \"\"\"\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX brot: <https://w3id.org/brot#>\n",
        "PREFIX brcomp: <https://w3id.org/brcomp#>\n",
        "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
        "\n",
        "SELECT DISTINCT ?inst ?ifcClass\n",
        "WHERE {\n",
        "  {?inst a brot:SubStructure .} UNION {?inst a brcomp:SubStructureComponent .}\n",
        "  ?inst a ?ifcClass .\n",
        "\n",
        "  FILTER(STRSTARTS(STR(?ifcClass), \"https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/\"))\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "results = g.query(query)\n",
        "\n",
        "# Print the results\n",
        "print(\"IFC Types that are brot:SubStructure or brcomp:SubStructureComponent:\")\n",
        "for row in results:\n",
        "    print(f\"{row.inst} - {row.ifcClass}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0cUTU_Ahzk5",
        "outputId": "7293fe88-27d5-4205-97cf-6a1cf2c35966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFC Types that are brot:SubStructure or brcomp:SubStructureComponent:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Querying enriched graph"
      ],
      "metadata": {
        "id": "gmHVMFEphz_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Extract substructure components. The expected result contains Abutment, Pier and Foundations.\n",
        "   This same query above on the enriched graph will return expected results.'''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/enriched_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query = \"\"\"\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX brot: <https://w3id.org/brot#>\n",
        "PREFIX brcomp: <https://w3id.org/brcomp#>\n",
        "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
        "\n",
        "SELECT DISTINCT ?inst ?ifcClass\n",
        "WHERE {\n",
        "  {?inst a brot:SubStructure .} UNION {?inst a brcomp:SubStructureComponent .}\n",
        "  ?inst a ?ifcClass .\n",
        "\n",
        "  FILTER(STRSTARTS(STR(?ifcClass), \"https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/\"))\n",
        "} LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "results = g.query(query)\n",
        "\n",
        "# Print the results\n",
        "print(\"IFC Types that are brot:SubStructure or brcomp:SubStructureComponent:\")\n",
        "for row in results:\n",
        "    print(f\"{row.inst} - {row.ifcClass}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMGZ_c_-1wgM",
        "outputId": "0f7dfa0f-cdc4-4486-f84a-779e133193ba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IFC Types that are brot:SubStructure or brcomp:SubStructureComponent:\n",
            "http://ifc-instance.org/instances/42796 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePart\n",
            "http://ifc-instance.org/instances/42796 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER\n",
            "http://ifc-instance.org/instances/42819 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePart\n",
            "http://ifc-instance.org/instances/42819 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER\n",
            "http://ifc-instance.org/instances/42841 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePart\n",
            "http://ifc-instance.org/instances/42841 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER\n",
            "http://ifc-instance.org/instances/42863 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePart\n",
            "http://ifc-instance.org/instances/42863 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER\n",
            "http://ifc-instance.org/instances/42885 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePart\n",
            "http://ifc-instance.org/instances/42885 - https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Count numbers of instances for each substructure element types. '''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/enriched_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query = \"\"\"\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX brot: <https://w3id.org/brot#>\n",
        "PREFIX brcomp: <https://w3id.org/brcomp#>\n",
        "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
        "\n",
        "SELECT ?ifcClass (COUNT(?inst) AS ?instance_count)\n",
        "WHERE {\n",
        "  {?inst a brot:SubStructure .} UNION {?inst a brcomp:SubStructureComponent .}\n",
        "  ?inst a ?ifcClass .\n",
        "  FILTER(STRSTARTS(STR(?ifcClass), \"https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/\"))\n",
        "}\n",
        "GROUP BY ?ifcClass\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "results = g.query(query)\n",
        "\n",
        "# Print the results\n",
        "print(\"Instance count per ifcClass:\")\n",
        "for row in results:\n",
        "    print(f\"Type: {row.ifcClass}, Instance Count: {row.instance_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awx9B--FmLvm",
        "outputId": "dcf38be2-5de7-44a3-f4c1-25f2cd478f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instance count per ifcClass:\n",
            "Type: https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePart, Instance Count: 24\n",
            "Type: https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER, Instance Count: 12\n",
            "Type: https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartFOUNDATION, Instance Count: 10\n",
            "Type: https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartABUTMENT, Instance Count: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Extract all ASB psets associated with each instances of Substructure elements.'''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/enriched_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query = \"\"\"\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX brot: <https://w3id.org/brot#>\n",
        "PREFIX brcomp: <https://w3id.org/brcomp#>\n",
        "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
        "PREFIX inst: <http://ifc-instance.org/instances/>\n",
        "\n",
        "SELECT ?asb ?asbType ?inst ?brcompClass\n",
        "WHERE {\n",
        "  ?inst a ?brcompClass .\n",
        "  ?brcompClass rdfs:subClassOf* brcomp:SubStructureComponent .\n",
        "  ?inst inst:hasAsbPset ?asb .\n",
        "  ?asb a ?asbType .\n",
        "}\n",
        "ORDER BY ?brcompClass\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "results = g.query(query)\n",
        "\n",
        "# Process and print the results\n",
        "current_brcomp_class = None  # Keep track of the current brcomp class\n",
        "for row in results:\n",
        "    if row.brcompClass != current_brcomp_class:\n",
        "        print(f\"\\nBrcomp Class: {row.brcompClass}\")  # Print brcomp class only when it changes\n",
        "        current_brcomp_class = row.brcompClass\n",
        "    print(f\"  Instance: {row.inst}, ASB Pset: {row.asb} & {row.asbType}\")  # Print ASB ID and Instance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6sTmco_M1yj",
        "outputId": "bbd230e7-5aac-4bf2-e495-4cb033f70f6d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Brcomp Class: https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartABUTMENT\n",
            "  Instance: http://ifc-instance.org/instances/43395, ASB Pset: http://asb-example.org/4B0W1WZO & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/43741, ASB Pset: http://asb-example.org/4B0W1WZR & http://asb-example.org/ASB_Pset_Feld\n",
            "\n",
            "Brcomp Class: https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartFOUNDATION\n",
            "  Instance: http://ifc-instance.org/instances/42952, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/42976, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WVO & http://asb-example.org/ASB_Pset_BelagAbdichtung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WXL & http://asb-example.org/ASB_Pset_Leitung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1X9V & http://asb-example.org/ASB_Pset_Bruecke\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115 & http://asb-example.org/ASB_Pset_Bauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115_0 & http://asb-example.org/ASB_Pset_Teilbauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43048, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43067, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43090, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43411, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43757, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43776, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43792, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "\n",
            "Brcomp Class: https://identifier.buildingsmart.org/uri/buildingsmart/ifc/4.3/class/IfcBridgePartPIER\n",
            "  Instance: http://ifc-instance.org/instances/42796, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42819, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42841, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42863, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42885, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42894, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "\n",
            "Brcomp Class: https://w3id.org/brcomp#Abutment\n",
            "  Instance: http://ifc-instance.org/instances/43395, ASB Pset: http://asb-example.org/4B0W1WZO & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/43741, ASB Pset: http://asb-example.org/4B0W1WZR & http://asb-example.org/ASB_Pset_Feld\n",
            "\n",
            "Brcomp Class: https://w3id.org/brcomp#Foundation\n",
            "  Instance: http://ifc-instance.org/instances/42952, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/42976, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WVO & http://asb-example.org/ASB_Pset_BelagAbdichtung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WXL & http://asb-example.org/ASB_Pset_Leitung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1X9V & http://asb-example.org/ASB_Pset_Bruecke\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115 & http://asb-example.org/ASB_Pset_Bauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115_0 & http://asb-example.org/ASB_Pset_Teilbauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43048, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43067, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43090, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43411, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43757, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43776, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43792, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "\n",
            "Brcomp Class: https://w3id.org/brcomp#Pier\n",
            "  Instance: http://ifc-instance.org/instances/42796, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42819, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42841, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42863, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42885, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42894, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "\n",
            "Brcomp Class: https://w3id.org/brcomp#SubStructureComponent\n",
            "  Instance: http://ifc-instance.org/instances/42796, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42819, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42841, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42863, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42885, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42894, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42952, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/42976, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WVO & http://asb-example.org/ASB_Pset_BelagAbdichtung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WXL & http://asb-example.org/ASB_Pset_Leitung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1X9V & http://asb-example.org/ASB_Pset_Bruecke\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115 & http://asb-example.org/ASB_Pset_Bauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115_0 & http://asb-example.org/ASB_Pset_Teilbauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43048, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43067, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43090, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43395, ASB Pset: http://asb-example.org/4B0W1WZO & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/43411, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43741, ASB Pset: http://asb-example.org/4B0W1WZR & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/43757, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43776, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43792, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/42796, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42819, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42841, ASB Pset: http://asb-example.org/4B0W1WZP & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42863, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42885, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42894, ASB Pset: http://asb-example.org/4B0W1WZQ & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/42952, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/42976, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WVO & http://asb-example.org/ASB_Pset_BelagAbdichtung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1WXL & http://asb-example.org/ASB_Pset_Leitung\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/4B0W1X9V & http://asb-example.org/ASB_Pset_Bruecke\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115 & http://asb-example.org/ASB_Pset_Bauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43032, ASB Pset: http://asb-example.org/B115_0 & http://asb-example.org/ASB_Pset_Teilbauwerk\n",
            "  Instance: http://ifc-instance.org/instances/43048, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43067, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43090, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43395, ASB Pset: http://asb-example.org/4B0W1WZO & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/43411, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43741, ASB Pset: http://asb-example.org/4B0W1WZR & http://asb-example.org/ASB_Pset_Feld\n",
            "  Instance: http://ifc-instance.org/instances/43757, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43776, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n",
            "  Instance: http://ifc-instance.org/instances/43792, ASB Pset: http://asb-example.org/4B0W1WX8 & http://asb-example.org/ASB_Pset_Gruendung\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Extract all ASB properties associated with Abutments. '''\n",
        "\n",
        "# Load the graph\n",
        "g = Graph()\n",
        "g.parse(\"/content/output/enriched_graph.ttl\", format=\"turtle\")\n",
        "\n",
        "# Define the SPARQL query\n",
        "query = \"\"\"\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX brot: <https://w3id.org/brot#>\n",
        "PREFIX brcomp: <https://w3id.org/brcomp#>\n",
        "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
        "PREFIX inst: <http://ifc-instance.org/instances/>\n",
        "PREFIX asb: <http://asb-example.org/>\n",
        "\n",
        "SELECT ?inst ?asbPset ?property ?value\n",
        "WHERE {\n",
        "  ?inst a/rdfs:subClassOf* brcomp:Abutment .\n",
        "  ?inst inst:hasAsbPset ?asbPset .\n",
        "  ?asbPset ?property ?value .\n",
        "  FILTER(?property != rdf:type) .\n",
        "}\n",
        "ORDER BY ?inst ?asbPset\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query\n",
        "results = g.query(query)\n",
        "\n",
        "# Process and print the results\n",
        "current_inst = None\n",
        "current_asb_pset = None\n",
        "for row in results:\n",
        "    if row.inst != current_inst:\n",
        "        print(f\"\\nInstance: {row.inst}\")\n",
        "        current_inst = row.inst\n",
        "        current_asb_pset = None  # Reset current_asb_pset when instance changes\n",
        "\n",
        "    if row.asbPset != current_asb_pset:\n",
        "        print(f\"  ASB Pset: {row.asbPset}\")\n",
        "        current_asb_pset = row.asbPset\n",
        "\n",
        "    print(f\"    Property: {row.property}, Value: {row.value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iuEv3W4i06KH",
        "outputId": "23c0754f-e4b1-464e-bf68-3e6eed934b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Instance: http://ifc-instance.org/instances/43395\n",
            "  ASB Pset: http://asb-example.org/4B0W1WZO\n",
            "    Property: http://asb-example.org/AMT, Value: 533\n",
            "    Property: http://asb-example.org/ANZAHL_ST, Value: 1\n",
            "    Property: http://asb-example.org/ART, Value: http://asb-example.org/40011100000000\n",
            "    Property: http://asb-example.org/BEARBEITER, Value: CODEKERK\n",
            "    Property: http://asb-example.org/BEARB_DAT, Value: 2002-08-27T08:34:54.999000\n",
            "    Property: http://asb-example.org/BEMERKUNG, Value: Widerlager 1\r\n",
            "***\n",
            "    Property: http://asb-example.org/BWNR, Value: http://asb-example.org/B115\n",
            "    Property: http://asb-example.org/FELDNR, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/FELD_NR, Value: http://asb-example.org/1\n",
            "    Property: http://asb-example.org/IDENT, Value: http://asb-example.org/4B0W1WZO\n",
            "    Property: http://asb-example.org/ID_NR, Value: http://asb-example.org/B115_0\n",
            "    Property: http://asb-example.org/REF_BRUCKE, Value: http://asb-example.org/4B0W1X9V\n",
            "    Property: http://asb-example.org/REF_FELDER, Value: http://asb-example.org/4B0W1X9W\n",
            "    Property: http://asb-example.org/SCHIFF_OEF, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/STUETZ_H, Value: 1.5\n",
            "    Property: http://asb-example.org/TEIL_BWNR, Value: http://asb-example.org/0\n",
            "    Property: http://www.w3.org/2002/07/owl#sameAs, Value: http://asb-example.org/4B0W1WZO\n",
            "    Property: http://asb-example.org/AMT, Value: 533\n",
            "    Property: http://asb-example.org/ANZAHL_ST, Value: 1\n",
            "    Property: http://asb-example.org/ART, Value: http://asb-example.org/40011100000000\n",
            "    Property: http://asb-example.org/BEARBEITER, Value: CODEKERK\n",
            "    Property: http://asb-example.org/BEARB_DAT, Value: 2002-08-27T08:34:54.999000\n",
            "    Property: http://asb-example.org/BEMERKUNG, Value: Widerlager 1\r\n",
            "***\n",
            "    Property: http://asb-example.org/BWNR, Value: http://asb-example.org/B115\n",
            "    Property: http://asb-example.org/FELDNR, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/FELD_NR, Value: http://asb-example.org/1\n",
            "    Property: http://asb-example.org/IDENT, Value: http://asb-example.org/4B0W1WZO\n",
            "    Property: http://asb-example.org/ID_NR, Value: http://asb-example.org/B115_0\n",
            "    Property: http://asb-example.org/REF_BRUCKE, Value: http://asb-example.org/4B0W1X9V\n",
            "    Property: http://asb-example.org/REF_FELDER, Value: http://asb-example.org/4B0W1X9W\n",
            "    Property: http://asb-example.org/SCHIFF_OEF, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/STUETZ_H, Value: 1.5\n",
            "    Property: http://asb-example.org/TEIL_BWNR, Value: http://asb-example.org/0\n",
            "    Property: http://www.w3.org/2002/07/owl#sameAs, Value: http://asb-example.org/4B0W1WZO\n",
            "    Property: http://asb-example.org/AMT, Value: 533\n",
            "    Property: http://asb-example.org/ANZAHL_ST, Value: 1\n",
            "    Property: http://asb-example.org/ART, Value: http://asb-example.org/40011100000000\n",
            "    Property: http://asb-example.org/BEARBEITER, Value: CODEKERK\n",
            "    Property: http://asb-example.org/BEARB_DAT, Value: 2002-08-27T08:34:54.999000\n",
            "    Property: http://asb-example.org/BEMERKUNG, Value: Widerlager 1\r\n",
            "***\n",
            "    Property: http://asb-example.org/BWNR, Value: http://asb-example.org/B115\n",
            "    Property: http://asb-example.org/FELDNR, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/FELD_NR, Value: http://asb-example.org/1\n",
            "    Property: http://asb-example.org/IDENT, Value: http://asb-example.org/4B0W1WZO\n",
            "    Property: http://asb-example.org/ID_NR, Value: http://asb-example.org/B115_0\n",
            "    Property: http://asb-example.org/REF_BRUCKE, Value: http://asb-example.org/4B0W1X9V\n",
            "    Property: http://asb-example.org/REF_FELDER, Value: http://asb-example.org/4B0W1X9W\n",
            "    Property: http://asb-example.org/SCHIFF_OEF, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/STUETZ_H, Value: 1.5\n",
            "    Property: http://asb-example.org/TEIL_BWNR, Value: http://asb-example.org/0\n",
            "    Property: http://www.w3.org/2002/07/owl#sameAs, Value: http://asb-example.org/4B0W1WZO\n",
            "\n",
            "Instance: http://ifc-instance.org/instances/43741\n",
            "  ASB Pset: http://asb-example.org/4B0W1WZR\n",
            "    Property: http://asb-example.org/AMT, Value: 533\n",
            "    Property: http://asb-example.org/ANZAHL_ST, Value: 1\n",
            "    Property: http://asb-example.org/ART, Value: http://asb-example.org/40011100000000\n",
            "    Property: http://asb-example.org/BEARBEITER, Value: CODEKERK\n",
            "    Property: http://asb-example.org/BEARB_DAT, Value: 2002-08-27T08:37:36\n",
            "    Property: http://asb-example.org/BEMERKUNG, Value: Widerlager 2\r\n",
            "***\n",
            "    Property: http://asb-example.org/BWNR, Value: http://asb-example.org/B115\n",
            "    Property: http://asb-example.org/FELDNR, Value: http://asb-example.org/3\n",
            "    Property: http://asb-example.org/FELD_NR, Value: http://asb-example.org/1\n",
            "    Property: http://asb-example.org/IDENT, Value: http://asb-example.org/4B0W1WZR\n",
            "    Property: http://asb-example.org/ID_NR, Value: http://asb-example.org/B115_0\n",
            "    Property: http://asb-example.org/REF_BRUCKE, Value: http://asb-example.org/4B0W1X9V\n",
            "    Property: http://asb-example.org/REF_FELDER, Value: http://asb-example.org/4B0W1X9Z\n",
            "    Property: http://asb-example.org/SCHIFF_OEF, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/STUETZ_H, Value: 1.5\n",
            "    Property: http://asb-example.org/STUETZ_W, Value: 18.0\n",
            "    Property: http://asb-example.org/TEIL_BWNR, Value: http://asb-example.org/0\n",
            "    Property: http://www.w3.org/2002/07/owl#sameAs, Value: http://asb-example.org/4B0W1WZR\n",
            "    Property: http://asb-example.org/AMT, Value: 533\n",
            "    Property: http://asb-example.org/ANZAHL_ST, Value: 1\n",
            "    Property: http://asb-example.org/ART, Value: http://asb-example.org/40011100000000\n",
            "    Property: http://asb-example.org/BEARBEITER, Value: CODEKERK\n",
            "    Property: http://asb-example.org/BEARB_DAT, Value: 2002-08-27T08:37:36\n",
            "    Property: http://asb-example.org/BEMERKUNG, Value: Widerlager 2\r\n",
            "***\n",
            "    Property: http://asb-example.org/BWNR, Value: http://asb-example.org/B115\n",
            "    Property: http://asb-example.org/FELDNR, Value: http://asb-example.org/3\n",
            "    Property: http://asb-example.org/FELD_NR, Value: http://asb-example.org/1\n",
            "    Property: http://asb-example.org/IDENT, Value: http://asb-example.org/4B0W1WZR\n",
            "    Property: http://asb-example.org/ID_NR, Value: http://asb-example.org/B115_0\n",
            "    Property: http://asb-example.org/REF_BRUCKE, Value: http://asb-example.org/4B0W1X9V\n",
            "    Property: http://asb-example.org/REF_FELDER, Value: http://asb-example.org/4B0W1X9Z\n",
            "    Property: http://asb-example.org/SCHIFF_OEF, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/STUETZ_H, Value: 1.5\n",
            "    Property: http://asb-example.org/STUETZ_W, Value: 18.0\n",
            "    Property: http://asb-example.org/TEIL_BWNR, Value: http://asb-example.org/0\n",
            "    Property: http://www.w3.org/2002/07/owl#sameAs, Value: http://asb-example.org/4B0W1WZR\n",
            "    Property: http://asb-example.org/AMT, Value: 533\n",
            "    Property: http://asb-example.org/ANZAHL_ST, Value: 1\n",
            "    Property: http://asb-example.org/ART, Value: http://asb-example.org/40011100000000\n",
            "    Property: http://asb-example.org/BEARBEITER, Value: CODEKERK\n",
            "    Property: http://asb-example.org/BEARB_DAT, Value: 2002-08-27T08:37:36\n",
            "    Property: http://asb-example.org/BEMERKUNG, Value: Widerlager 2\r\n",
            "***\n",
            "    Property: http://asb-example.org/BWNR, Value: http://asb-example.org/B115\n",
            "    Property: http://asb-example.org/FELDNR, Value: http://asb-example.org/3\n",
            "    Property: http://asb-example.org/FELD_NR, Value: http://asb-example.org/1\n",
            "    Property: http://asb-example.org/IDENT, Value: http://asb-example.org/4B0W1WZR\n",
            "    Property: http://asb-example.org/ID_NR, Value: http://asb-example.org/B115_0\n",
            "    Property: http://asb-example.org/REF_BRUCKE, Value: http://asb-example.org/4B0W1X9V\n",
            "    Property: http://asb-example.org/REF_FELDER, Value: http://asb-example.org/4B0W1X9Z\n",
            "    Property: http://asb-example.org/SCHIFF_OEF, Value: http://asb-example.org/0\n",
            "    Property: http://asb-example.org/STUETZ_H, Value: 1.5\n",
            "    Property: http://asb-example.org/STUETZ_W, Value: 18.0\n",
            "    Property: http://asb-example.org/TEIL_BWNR, Value: http://asb-example.org/0\n",
            "    Property: http://www.w3.org/2002/07/owl#sameAs, Value: http://asb-example.org/4B0W1WZR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Single Entity"
      ],
      "metadata": {
        "id": "RG1-0Idw1xEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph, URIRef\n",
        "from typing import Union\n",
        "\n",
        "def extract_direct_connections(\n",
        "    input_file: str,\n",
        "    target_object: str,\n",
        "    output_file: str,\n",
        "    include_inverse: bool = True\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Extract triples that directly connect to a specific object from a TTL file.\n",
        "    Preserves namespace bindings from input to output.\n",
        "\n",
        "    Args:\n",
        "        input_file: Path to input TTL file\n",
        "        target_object: URI or literal of the target object\n",
        "        output_file: Path to output TTL file\n",
        "        include_inverse: Whether to include triples where target is subject\n",
        "    \"\"\"\n",
        "    # Create new graph with namespaces\n",
        "    output_graph, namespaces = create_and_bind_graph()\n",
        "\n",
        "    # Load the input graph\n",
        "    input_graph = Graph()\n",
        "    input_graph.parse(input_file, format=\"turtle\")\n",
        "\n",
        "    # Copy namespace bindings from input graph\n",
        "    for prefix, namespace in input_graph.namespaces():\n",
        "        if prefix not in [p.lower() for p in namespaces.keys()]:\n",
        "            output_graph.bind(prefix, namespace)\n",
        "\n",
        "    # Convert target_object to URIRef if it's a URI\n",
        "    target = URIRef(target_object) if target_object.startswith(\"http\") else target_object\n",
        "\n",
        "    # Get direct triples where target is the object\n",
        "    for s, p, o in input_graph.triples((None, None, target)):\n",
        "        output_graph.add((s, p, o))\n",
        "\n",
        "    if include_inverse:\n",
        "        # Get direct triples where target is the subject\n",
        "        for s, p, o in input_graph.triples((target, None, None)):\n",
        "            output_graph.add((s, p, o))\n",
        "\n",
        "    # Save the output graph with preserved namespaces\n",
        "    output_graph.serialize(\n",
        "        destination=output_file,\n",
        "        format=\"turtle\"\n",
        "    )\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"Original graph: {len(input_graph)} triples\")\n",
        "    print(f\"Extracted graph: {len(output_graph)} triples\")\n",
        "    print(f\"Preserved namespaces: {len(list(output_graph.namespaces()))} namespaces\")\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "extract_direct_connections(\n",
        "    input_file=\"/content/output/ifc_graph.ttl\",\n",
        "    target_object=\"http://ifc-instance.org/instances/43395\",\n",
        "    output_file=\"/content/output/singleElement_ifc.ttl\",\n",
        "    include_inverse=True,  # Include triples where target is the subject\n",
        ")\n",
        "\n",
        "extract_direct_connections(\n",
        "    input_file=\"/content/output/merged_graph.ttl\",\n",
        "    target_object=\"http://ifc-instance.org/instances/43395\",\n",
        "    output_file=\"/content/output/singleElement_merged.ttl\",\n",
        "    include_inverse=True,  # Include triples where target is the subject\n",
        ")\n",
        "\n",
        "extract_direct_connections(\n",
        "    input_file=\"/content/output/linked_graph.ttl\",\n",
        "    target_object=\"http://ifc-instance.org/instances/43395\",\n",
        "    output_file=\"/content/output/singleElement_linked.ttl\",\n",
        "    include_inverse=True,  # Include triples where target is the subject\n",
        ")\n",
        "\n",
        "extract_direct_connections(\n",
        "    input_file=\"/content/output/enriched_graph.ttl\",\n",
        "    target_object=\"http://ifc-instance.org/instances/43395\",\n",
        "    output_file=\"/content/output/singleElement_enriched.ttl\",\n",
        "    include_inverse=True,  # Include triples where target is the subject\n",
        ")\n"
      ],
      "metadata": {
        "id": "DnVA68DcXwXW",
        "outputId": "fa063423-954e-47ec-d259-f10a2b2c477b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original graph: 202 triples\n",
            "Extracted graph: 5 triples\n",
            "Preserved namespaces: 35 namespaces\n",
            "Original graph: 796 triples\n",
            "Extracted graph: 6 triples\n",
            "Preserved namespaces: 35 namespaces\n",
            "Original graph: 1340 triples\n",
            "Extracted graph: 6 triples\n",
            "Preserved namespaces: 37 namespaces\n",
            "Original graph: 3230 triples\n",
            "Extracted graph: 12 triples\n",
            "Preserved namespaces: 37 namespaces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualisation\n",
        "custom_options = {\"physics\": {\n",
        "    \"barnesHut\": {\n",
        "        \"gravitationalConstant\": -2000,\n",
        "        \"centralGravity\": 0.3,\n",
        "        \"springLength\": 95,\n",
        "        \"springConstant\": 0.04\n",
        "        }\n",
        "    }}\n",
        "\n",
        "visualize_rdf(\"/content/output/singleElement_ifc.ttl\", \"/content/output/singleElement_ifc.html\", custom_options)\n",
        "# visualize_rdf(\"/content/output/singleElement_merged.ttl\", \"/content/output/singleElement_merged.html\", custom_options)\n",
        "# visualize_rdf(\"/content/output/singleElement_linked.ttl\", \"/content/output/singleElement_linked.html\", custom_options)\n",
        "visualize_rdf(\"/content/output/singleElement_enriched.ttl\", \"/content/output/singleElement_enriched.html\", custom_options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9T-G1w5HVEpM",
        "outputId": "8fb29bf5-f73e-496e-9dc4-350cb4f924c9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization saved as /content/output/singleElement_ifc.html\n",
            "Visualization saved as /content/output/singleElement_enriched.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'pyvis.network.Network'> |N|=12 |E|=12"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}